{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/amine.mcharrak/miniconda3/envs/pcax24/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix loaded from ../data/G_A_init_t_ordered_adj_matrix.npy\n",
      "Adjacency matrix loaded from ../data/G_A_init_t_ordered_dag_adj_matrix.npy\n",
      "Adjacency matrix loaded from ../data/ER_adj_matrix.npy\n",
      "Adjacency matrix loaded from ../data/ER_dag_adj_matrix.npy\n",
      "20.0\n",
      "['Mask', 'Optim', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_mask', '_misc', '_optim', '_serialisation', 'load_params', 'm', 'save_params', 'step']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting CUDA device(s) : [0]\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "import os\n",
    "\n",
    "# choose the GPU to use\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# disable preallocation of memory\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "# pcax\n",
    "import pcax as px\n",
    "import pcax.predictive_coding as pxc\n",
    "import pcax.nn as pxnn\n",
    "import pcax.functional as pxf\n",
    "import pcax.utils as pxu\n",
    "\n",
    "# 3rd party\n",
    "import jax\n",
    "from jax import jit\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import timeit\n",
    "\n",
    "# own\n",
    "import causal_helpers\n",
    "from causal_helpers import simulate_dag, simulate_parameter, simulate_linear_sem, simulate_linear_sem_cyclic\n",
    "from causal_helpers import load_adjacency_matrix, set_random_seed, plot_adjacency_matrices\n",
    "\n",
    "# Set random seed\n",
    "seed = 23\n",
    "set_random_seed(seed)\n",
    "\n",
    "# causal libraries\n",
    "import cdt, castle\n",
    "\n",
    "# causal metrics\n",
    "from cdt.metrics import precision_recall, SHD, SID\n",
    "from castle.metrics import MetricsDAG\n",
    "from castle.common import GraphDAG\n",
    "from causallearn.graph.SHD import SHD as SHD_causallearn\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Load the actual connectome data\n",
    "\n",
    "# %%\n",
    "# load the weighted adjacency matrices for ER and connectome\n",
    "\n",
    "# Specify the folder where the adjacency matrices were saved\n",
    "folder = '../data/'\n",
    "\n",
    "# Example usage to load the saved adjacency matrices\n",
    "G_A_init_t_ordered_adj_matrix = load_adjacency_matrix(os.path.join(folder, 'G_A_init_t_ordered_adj_matrix.npy'))\n",
    "G_A_init_t_ordered_dag_adj_matrix = load_adjacency_matrix(os.path.join(folder, 'G_A_init_t_ordered_dag_adj_matrix.npy'))\n",
    "ER = load_adjacency_matrix(os.path.join(folder, 'ER_adj_matrix.npy'))\n",
    "ER_dag = load_adjacency_matrix(os.path.join(folder, 'ER_dag_adj_matrix.npy'))\n",
    "\n",
    "# Change name of the connectome adjacency matrix to C and C_dag\n",
    "C = G_A_init_t_ordered_adj_matrix\n",
    "C_dag = G_A_init_t_ordered_dag_adj_matrix\n",
    "\n",
    "# Now ensure that both DAG adjacency matrices are binary, if they aren't already\n",
    "ER_dag_bin = (ER_dag != 0).astype(int)\n",
    "C_dag_bin = (C_dag != 0).astype(int)\n",
    "\n",
    "ER_true = ER_dag_bin\n",
    "C_true = C_dag_bin\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Create data to debug and implement the pcax version of NOTEARS\n",
    "\n",
    "# %%\n",
    "# actual data\n",
    "#B_true = simulate_dag(d=100, s0=400, graph_type='ER') # ER4\n",
    "# debugging data\n",
    "#B_true = simulate_dag(d=10, s0=20, graph_type='ER') # ER2\n",
    "\n",
    "\n",
    "#B_true = C_dag_bin # if you want to use the connectome-based DAG # best performance so far with 200,000 samples: 0.06 \n",
    "#B_true = ER_dag_bin # if you want to use the ER-based DAG\n",
    "\n",
    "#B_true = simulate_dag(d=5, s0=10, graph_type='ER') # ER2\n",
    "#B_true = simulate_dag(d=50, s0=100, graph_type='ER') # ER2\n",
    "B_true = simulate_dag(d=10, s0=20, graph_type='ER') # ER2\n",
    "#B_true = simulate_dag(d=100, s0=200, graph_type='ER') # ER2\n",
    "#B_true = simulate_dag(d=279, s0=558, graph_type='ER') # ER2\n",
    "\n",
    "# create equivalent ER4 and ER6 graphs\n",
    "#B_true = simulate_dag(d=279, s0=1116, graph_type='ER') # ER4\n",
    "#B_true = simulate_dag(d=279, s0=1674, graph_type='ER') # ER6\n",
    "\n",
    "# create equivalent SF4 and SF6 graphs\n",
    "#B_true = simulate_dag(d=100, s0=600, graph_type='SF') # SF6\n",
    "#B_true = simulate_dag(d=279, s0=1116, graph_type='SF') # SF4\n",
    "#B_true = simulate_dag(d=279, s0=1674, graph_type='SF') # SF6\n",
    "\n",
    "\n",
    "# create simple data using simulate_dag method from causal_helpers with expected number of edges (s0) and number of nodes (d)\n",
    "#B_true = simulate_dag(d=100, s0=199, graph_type='ER') # we use p≈0.040226 for the connectome-based ER_dag graph. This means that the expected number of edges is 0.040226 * d * (d-1) / 2\n",
    "# examples: d=50 -> s0=49 (works), d=100 -> s0=199, d=200 -> s0=800\n",
    "W_true = simulate_parameter(B_true)\n",
    "\n",
    "# sample data from the linear SEM\n",
    "# actual data\n",
    "#X = simulate_linear_sem(W_true, n=25000, sem_type='gauss')\n",
    "# for debugging\n",
    "X = simulate_linear_sem(W_true, n=1000, sem_type='gauss')\n",
    "#X = simulate_linear_sem(W_true, n=2500, sem_type='gauss')\n",
    "#X = simulate_linear_sem(W_true, n=6250, sem_type='gauss')\n",
    "#X = simulate_linear_sem(W_true, n=50000, sem_type='gauss')\n",
    "#X = simulate_linear_sem(W_true, n=100000, sem_type='gauss') # 1000*(279**2)/(20**2) = 194602\n",
    "\n",
    "# now standardized data, where each variable is normalized to unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "# NOTE: you may not write positional arguments after keyword arguments. \n",
    "# That is, the values that you are passing positionally have to come first!\n",
    "\n",
    "# create a dataset using the simulated data\n",
    "# NOTE: NOTEARS paper uses n=1000 for graph with d=20.\n",
    "# NOTE: d... number of nodes, p=d^2... number of parameters, n... number of samples. Then: comparing p1=d1^2 vs p2=d2^2 we have that: n1/p1 must be equal to n2/p2\n",
    "# Thus we have n2 = n1 * p2 / p1. For the case of d2=100 we have that n2 = (n1*p2)/p1 = 1000*(100^2)/(20^2) = 25000 \n",
    "# we should expect to use that many samples actually to be able to learn the graph in a comparable way.\n",
    "#dataset = IIDSimulation(W=W_true, n=25000, method='linear', sem_type='gauss')\n",
    "#true_dag, X = dataset.B, dataset.X\n",
    "\n",
    "# %%\n",
    "print(np.sum(B_true))\n",
    "\n",
    "# %%\n",
    "import pcax.utils as pxu\n",
    "print(dir(pxu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1: single vode\n",
    "# %%\n",
    "# v1: single vode\n",
    "class Complete_Graph(pxc.EnergyModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim: int, \n",
    "        n_nodes: int, \n",
    "        hidden_dim: int = 3, \n",
    "        act_fn: Callable[[jax.Array], jax.Array] = jax.nn.relu,\n",
    "        has_bias: bool = False\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = px.static(input_dim)\n",
    "        self.n_nodes = px.static(n_nodes)\n",
    "        self.hidden_dim = px.static(hidden_dim)\n",
    "        self.has_bias = has_bias\n",
    "        self.act_fn = px.static(act_fn)\n",
    "\n",
    "        # Initialize MLPs for each connection (n_nodes x n_nodes matrix of MLPs)\n",
    "        self.mlp_layers = []\n",
    "        # Initialize vodes only for hidden layers of MLPs\n",
    "        self.mlp_vodes = []\n",
    "        \n",
    "        for i in range(n_nodes):\n",
    "            node_layers = []\n",
    "            node_vodes = []\n",
    "            for j in range(n_nodes):\n",
    "                # Create MLP: input_dim -> hidden_dim -> input_dim\n",
    "                mlp = [\n",
    "                    pxnn.Linear(input_dim, hidden_dim, bias=has_bias),\n",
    "                    pxnn.Linear(hidden_dim, input_dim, bias=has_bias)\n",
    "                ]\n",
    "                # Create vode only for hidden layer\n",
    "                vode = pxc.Vode((hidden_dim,))\n",
    "                node_layers.append(mlp)\n",
    "                node_vodes.append(vode)\n",
    "\n",
    "            self.mlp_layers.append(node_layers)\n",
    "            self.mlp_vodes.append(node_vodes)\n",
    "\n",
    "        # Initialize adjacency matrix as a LayerParam\n",
    "        init_weights = jnp.ones((n_nodes, n_nodes))\n",
    "        init_weights = jax.numpy.fill_diagonal(init_weights, 0.0, inplace=False)\n",
    "        self.adj_weights = pxnn.LayerParam(init_weights)\n",
    "\n",
    "        # Initialize main node vode\n",
    "        self.vodes = [pxc.Vode((n_nodes, input_dim))]\n",
    "        #self.vodes = [pxc.Vode((n_nodes, ))]\n",
    "\n",
    "    def freeze_nodes(self, freeze=True):\n",
    "        # Only freeze the main node vode\n",
    "        self.vodes[0].h.frozen = freeze\n",
    "\n",
    "    def are_vodes_frozen(self):\n",
    "        return self.vodes[0].h.frozen\n",
    "    \n",
    "    def get_W(self):\n",
    "        \"\"\"Returns the weighted adjacency matrix.\"\"\"\n",
    "        return self.adj_weights.get()\n",
    "\n",
    "    #def mlp_forward(self, x, i, j):\n",
    "    #    \"\"\"Forward pass through MLP for connection i->j with nonlinear activation.\"\"\"\n",
    "    #\n",
    "    #    # print shape of x inside mlp_forward\n",
    "    #    print(f\"The shape of x inside mlp_forward: {x.shape}\")\n",
    "    #\n",
    "    #    # print value of self.hidden_dim then print self.hidden_dim.get()\n",
    "    #    #print(f\"This is self.hidden_dim: {self.hidden_dim}\") # wrong because it is a px.static object\n",
    "    #    print(f\"The is self.hidden_dim.get(): {self.hidden_dim.get()}\") # correct\n",
    "    #    \n",
    "    #    if i == j:  # Skip self-loops but initialize Vode cache\n",
    "    #        # Create a dummy input for the Vode module to initialize the cache\n",
    "    #        dummy_input = jnp.zeros((self.hidden_dim.get(),))\n",
    "    #        out = self.mlp_vodes[i][j](dummy_input)\n",
    "    #        return out\n",
    "    #\n",
    "    #    # print the shape of x\n",
    "    #    print(f\"The shape of x in mlp_forward: {x.shape}\")\n",
    "    #\n",
    "    #    # First linear layer\n",
    "    #    h = self.mlp_layers[i][j][0](x)\n",
    "    #    # Apply activation and vode on hidden layer (vode not frozen)\n",
    "    #    h = self.act_fn(h)\n",
    "    #    h = self.mlp_vodes[i][j](h)\n",
    "    #    \n",
    "    #    # Final linear layer (no vode on output)\n",
    "    #    out = self.mlp_layers[i][j][1](h)\n",
    "    #    \n",
    "    #    return out\n",
    "\n",
    "    def mlp_forward(self, x, i, j):\n",
    "        \"\"\"Forward pass through MLP for connection i->j with nonlinear activation.\"\"\"\n",
    "        if i == j:  # Skip self-loops but initialize Vode cache\n",
    "            # Create a dummy input for the Vode module to initialize the cache\n",
    "            dummy_input = jnp.zeros((self.hidden_dim.get(),))  # Use hidden_dim instead of input_dim\n",
    "            # Ensure hidden_dim.get() returns a concrete integer. If not, hardcode the value.\n",
    "            # For example, if hidden_dim is 3:\n",
    "            # dummy_input = jnp.zeros((3,))\n",
    "            self.mlp_vodes[i][j](dummy_input)\n",
    "            return 0.0\n",
    "\n",
    "        # First linear layer\n",
    "        h = self.mlp_layers[i][j][0](x)\n",
    "        # Apply nonlinear activation\n",
    "        h = self.act_fn(h)\n",
    "        # Pass through the Vode module\n",
    "        h = self.mlp_vodes[i][j](h)\n",
    "\n",
    "        # Final linear layer\n",
    "        out = self.mlp_layers[i][j][1](h)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __call__(self, x=None):\n",
    "        n_nodes = self.n_nodes.get()\n",
    "        input_dim = self.input_dim.get()\n",
    "        \n",
    "        if x is not None:\n",
    "\n",
    "            # Initialize nodes with given data\n",
    "            reshaped_x = x.reshape(n_nodes, input_dim)            \n",
    "            \n",
    "\n",
    "            # print the shape of x\n",
    "            print(f\"The shape of x in __call__ if statement: {x.shape}\")\n",
    "            # print the shape of reshaped_x\n",
    "            print(f\"The shape of reshaped_x in __call__ if statement: {reshaped_x.shape}\")\n",
    "\n",
    "\n",
    "            for j in range(n_nodes):\n",
    "                for i in range(n_nodes):\n",
    "                        mlp_out = self.mlp_forward(reshaped_x[i], i, j)      \n",
    "\n",
    "            # print successfully finished mlp_forward in __call__ for x is not None\n",
    "            print(\"Successfully finished mlp_forward in __call__ for x is not None\")\n",
    "\n",
    "            self.vodes[0](reshaped_x)\n",
    "\n",
    "        else:\n",
    "            # Get current node values\n",
    "            x_ = self.vodes[0].get('h')\n",
    "\n",
    "            reshaped_x_ = x_.reshape(n_nodes, input_dim)\n",
    "            \n",
    "            # print the shape of x_\n",
    "            print(f\"The shape of x_ in __call__ else statement: {x_.shape}\")\n",
    "            # print the shape of reshaped_x_\n",
    "            print(f\"The shape of reshaped_x_ in __call__ else statement: {reshaped_x_.shape}\")\n",
    "\n",
    "            # Compute weighted sum of MLP outputs for each node\n",
    "            outputs = []\n",
    "            for j in range(n_nodes):\n",
    "                node_output = 0\n",
    "                for i in range(n_nodes):\n",
    "                    # Apply MLP and weight by adjacency matrix entry\n",
    "                    mlp_out = self.mlp_forward(x_[i], i, j)\n",
    "                    node_output += self.adj_weights.get()[i, j] * mlp_out\n",
    "                outputs.append(node_output)\n",
    "            \n",
    "            # Stack outputs and update vodes\n",
    "            output = jnp.stack(outputs)\n",
    "            self.vodes[0](output)\n",
    "\n",
    "            # run the forward pass for each node to have VodeParam values that are not None\n",
    "            #for j in range(n_nodes):\n",
    "            #    for i in range(n_nodes):\n",
    "            #            mlp_out = self.mlp_forward(x_[i], i, j)\n",
    "\n",
    "        return self.vodes[0].get('h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]]\n",
      "\n",
      "(10, 10)\n",
      "(Complete_Graph):\n",
      "  .has_bias: True\n",
      "  .mlp_layers[0][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_vodes[0][0].h: VodeParam(None)\n",
      "  .mlp_vodes[0][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][1].h: VodeParam(None)\n",
      "  .mlp_vodes[0][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][2].h: VodeParam(None)\n",
      "  .mlp_vodes[0][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][3].h: VodeParam(None)\n",
      "  .mlp_vodes[0][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][4].h: VodeParam(None)\n",
      "  .mlp_vodes[0][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][5].h: VodeParam(None)\n",
      "  .mlp_vodes[0][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][6].h: VodeParam(None)\n",
      "  .mlp_vodes[0][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][7].h: VodeParam(None)\n",
      "  .mlp_vodes[0][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][8].h: VodeParam(None)\n",
      "  .mlp_vodes[0][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][9].h: VodeParam(None)\n",
      "  .mlp_vodes[0][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][0].h: VodeParam(None)\n",
      "  .mlp_vodes[1][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][1].h: VodeParam(None)\n",
      "  .mlp_vodes[1][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][2].h: VodeParam(None)\n",
      "  .mlp_vodes[1][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][3].h: VodeParam(None)\n",
      "  .mlp_vodes[1][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][4].h: VodeParam(None)\n",
      "  .mlp_vodes[1][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][5].h: VodeParam(None)\n",
      "  .mlp_vodes[1][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][6].h: VodeParam(None)\n",
      "  .mlp_vodes[1][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][7].h: VodeParam(None)\n",
      "  .mlp_vodes[1][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][8].h: VodeParam(None)\n",
      "  .mlp_vodes[1][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][9].h: VodeParam(None)\n",
      "  .mlp_vodes[1][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][0].h: VodeParam(None)\n",
      "  .mlp_vodes[2][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][1].h: VodeParam(None)\n",
      "  .mlp_vodes[2][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][2].h: VodeParam(None)\n",
      "  .mlp_vodes[2][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][3].h: VodeParam(None)\n",
      "  .mlp_vodes[2][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][4].h: VodeParam(None)\n",
      "  .mlp_vodes[2][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][5].h: VodeParam(None)\n",
      "  .mlp_vodes[2][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][6].h: VodeParam(None)\n",
      "  .mlp_vodes[2][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][7].h: VodeParam(None)\n",
      "  .mlp_vodes[2][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][8].h: VodeParam(None)\n",
      "  .mlp_vodes[2][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][9].h: VodeParam(None)\n",
      "  .mlp_vodes[2][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][0].h: VodeParam(None)\n",
      "  .mlp_vodes[3][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][1].h: VodeParam(None)\n",
      "  .mlp_vodes[3][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][2].h: VodeParam(None)\n",
      "  .mlp_vodes[3][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][3].h: VodeParam(None)\n",
      "  .mlp_vodes[3][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][4].h: VodeParam(None)\n",
      "  .mlp_vodes[3][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][5].h: VodeParam(None)\n",
      "  .mlp_vodes[3][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][6].h: VodeParam(None)\n",
      "  .mlp_vodes[3][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][7].h: VodeParam(None)\n",
      "  .mlp_vodes[3][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][8].h: VodeParam(None)\n",
      "  .mlp_vodes[3][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][9].h: VodeParam(None)\n",
      "  .mlp_vodes[3][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][0].h: VodeParam(None)\n",
      "  .mlp_vodes[4][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][1].h: VodeParam(None)\n",
      "  .mlp_vodes[4][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][2].h: VodeParam(None)\n",
      "  .mlp_vodes[4][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][3].h: VodeParam(None)\n",
      "  .mlp_vodes[4][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][4].h: VodeParam(None)\n",
      "  .mlp_vodes[4][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][5].h: VodeParam(None)\n",
      "  .mlp_vodes[4][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][6].h: VodeParam(None)\n",
      "  .mlp_vodes[4][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][7].h: VodeParam(None)\n",
      "  .mlp_vodes[4][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][8].h: VodeParam(None)\n",
      "  .mlp_vodes[4][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][9].h: VodeParam(None)\n",
      "  .mlp_vodes[4][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][0].h: VodeParam(None)\n",
      "  .mlp_vodes[5][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][1].h: VodeParam(None)\n",
      "  .mlp_vodes[5][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][2].h: VodeParam(None)\n",
      "  .mlp_vodes[5][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][3].h: VodeParam(None)\n",
      "  .mlp_vodes[5][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][4].h: VodeParam(None)\n",
      "  .mlp_vodes[5][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][5].h: VodeParam(None)\n",
      "  .mlp_vodes[5][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][6].h: VodeParam(None)\n",
      "  .mlp_vodes[5][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][7].h: VodeParam(None)\n",
      "  .mlp_vodes[5][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][8].h: VodeParam(None)\n",
      "  .mlp_vodes[5][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][9].h: VodeParam(None)\n",
      "  .mlp_vodes[5][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][0].h: VodeParam(None)\n",
      "  .mlp_vodes[6][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][1].h: VodeParam(None)\n",
      "  .mlp_vodes[6][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][2].h: VodeParam(None)\n",
      "  .mlp_vodes[6][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][3].h: VodeParam(None)\n",
      "  .mlp_vodes[6][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][4].h: VodeParam(None)\n",
      "  .mlp_vodes[6][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][5].h: VodeParam(None)\n",
      "  .mlp_vodes[6][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][6].h: VodeParam(None)\n",
      "  .mlp_vodes[6][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][7].h: VodeParam(None)\n",
      "  .mlp_vodes[6][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][8].h: VodeParam(None)\n",
      "  .mlp_vodes[6][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][9].h: VodeParam(None)\n",
      "  .mlp_vodes[6][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][0].h: VodeParam(None)\n",
      "  .mlp_vodes[7][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][1].h: VodeParam(None)\n",
      "  .mlp_vodes[7][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][2].h: VodeParam(None)\n",
      "  .mlp_vodes[7][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][3].h: VodeParam(None)\n",
      "  .mlp_vodes[7][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][4].h: VodeParam(None)\n",
      "  .mlp_vodes[7][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][5].h: VodeParam(None)\n",
      "  .mlp_vodes[7][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][6].h: VodeParam(None)\n",
      "  .mlp_vodes[7][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][7].h: VodeParam(None)\n",
      "  .mlp_vodes[7][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][8].h: VodeParam(None)\n",
      "  .mlp_vodes[7][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][9].h: VodeParam(None)\n",
      "  .mlp_vodes[7][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][0].h: VodeParam(None)\n",
      "  .mlp_vodes[8][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][1].h: VodeParam(None)\n",
      "  .mlp_vodes[8][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][2].h: VodeParam(None)\n",
      "  .mlp_vodes[8][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][3].h: VodeParam(None)\n",
      "  .mlp_vodes[8][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][4].h: VodeParam(None)\n",
      "  .mlp_vodes[8][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][5].h: VodeParam(None)\n",
      "  .mlp_vodes[8][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][6].h: VodeParam(None)\n",
      "  .mlp_vodes[8][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][7].h: VodeParam(None)\n",
      "  .mlp_vodes[8][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][8].h: VodeParam(None)\n",
      "  .mlp_vodes[8][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][9].h: VodeParam(None)\n",
      "  .mlp_vodes[8][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][0].h: VodeParam(None)\n",
      "  .mlp_vodes[9][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][1].h: VodeParam(None)\n",
      "  .mlp_vodes[9][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][2].h: VodeParam(None)\n",
      "  .mlp_vodes[9][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][3].h: VodeParam(None)\n",
      "  .mlp_vodes[9][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][4].h: VodeParam(None)\n",
      "  .mlp_vodes[9][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][5].h: VodeParam(None)\n",
      "  .mlp_vodes[9][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][6].h: VodeParam(None)\n",
      "  .mlp_vodes[9][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][7].h: VodeParam(None)\n",
      "  .mlp_vodes[9][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][8].h: VodeParam(None)\n",
      "  .mlp_vodes[9][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][9].h: VodeParam(None)\n",
      "  .mlp_vodes[9][9].cache: Cache(params=None)\n",
      "  .adj_weights: LayerParam([10,10], float32)\n",
      "  .vodes[0].h: VodeParam(None)\n",
      "  .vodes[0].cache: Cache(params=None)\n",
      "True\n",
      "False\n",
      "MAE between the true adjacency matrix and an all-zero matrix:  0.27927107\n",
      "SHD between the true adjacency matrix and an all-zero matrix:  20.0\n",
      "Forward: Starting\n",
      "The shape of x in __call__ if statement: (10,)\n",
      "The shape of reshaped_x in __call__ if statement: (10, 1)\n",
      "Successfully finished mlp_forward in __call__ for x is not None\n",
      "Forward: Completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage\n",
    "input_dim = 1\n",
    "n_nodes = X.shape[1]\n",
    "#model = Complete_Graph(input_dim, n_nodes, has_bias=False)\n",
    "model = Complete_Graph(input_dim, n_nodes, has_bias=True, act_fn=jax.nn.leaky_relu)\n",
    "\n",
    "# Get weighted adjacency matrix\n",
    "W = model.get_W()\n",
    "print(W)\n",
    "print()\n",
    "print(W.shape)\n",
    "print(model)\n",
    "\n",
    "\n",
    "# Freezing all nodes\n",
    "model.freeze_nodes(freeze=True)\n",
    "\n",
    "# Check if all nodes are frozen\n",
    "print(model.are_vodes_frozen())\n",
    "\n",
    "# Unfreezing all nodes\n",
    "model.freeze_nodes(freeze=False)\n",
    "\n",
    "# Check if all nodes are frozen\n",
    "print(model.are_vodes_frozen())\n",
    "\n",
    "# %%\n",
    "# TODO: make the below params global or input to the functions in which it is used.\n",
    "w_learning_rate = 1e-2 # Notes: 5e-1 is too high\n",
    "h_learning_rate = 1e-2\n",
    "T = 64\n",
    "\n",
    "nm_epochs = 2000\n",
    "batch_size = 128\n",
    "\n",
    "lam_h = 1e1 # 2e2 -> 5e2 # this move works well! FIRST MOVE\n",
    "lam_l1 = 1e-3 # 1e-2 -> 3e-2 # this move works well! SECOND MOVE\n",
    "\n",
    "# %%\n",
    "# Training and evaluation functions\n",
    "@pxf.vmap(pxu.Mask(pxc.VodeParam | pxc.VodeParam.Cache, (None, 0)), in_axes=(0,), out_axes=0)\n",
    "def forward(x, *, model: Complete_Graph):\n",
    "    print(\"Forward: Starting\")\n",
    "    result = model(x)\n",
    "    print(\"Forward: Completed\")\n",
    "    return result\n",
    "\n",
    "@pxf.vmap(pxu.Mask(pxc.VodeParam | pxc.VodeParam.Cache, (None, 0)), out_axes=(None, 0), axis_name=\"batch\")\n",
    "def energy(*, model: Complete_Graph):\n",
    "    print(\"Energy: Starting computation\")\n",
    "    x_ = model(None)\n",
    "    print(\"Energy: Got model output\")\n",
    "    \n",
    "    W = model.get_W()\n",
    "    d = model.n_nodes.get()\n",
    "    print(f\"Energy: Got W (shape: {W.shape}) and d: {d}\")\n",
    "\n",
    "    # PC energy term\n",
    "    energy = model.energy()\n",
    "    print(f\"Energy: PC energy term: {energy}\")\n",
    "\n",
    "    # L1 regularization using adjacency matrix\n",
    "    l1_reg = jnp.sum(jnp.abs(W))\n",
    "    print(f\"Energy: L1 reg term: {l1_reg}\")\n",
    "\n",
    "    # DAG constraint\n",
    "    h_reg = jnp.trace(jax.scipy.linalg.expm(jnp.multiply(W, W))) - d\n",
    "    print(f\"Energy: DAG constraint term: {h_reg}\")\n",
    "    \n",
    "    # Combined loss\n",
    "    obj = jax.lax.pmean(energy, axis_name=\"batch\") + lam_h * h_reg + lam_l1 * l1_reg\n",
    "    print(f\"Energy: Final objective: {obj}\")\n",
    "\n",
    "    return obj, x_\n",
    "\n",
    "@pxf.jit(static_argnums=0)\n",
    "def train_on_batch(T: int, x: jax.Array, *, model: Complete_Graph, optim_w: pxu.Optim, optim_h: pxu.Optim):\n",
    "    print(\"1. Starting train_on_batch\")  \n",
    "\n",
    "    model.train()\n",
    "    print(\"2. Model set to train mode\")\n",
    "\n",
    "    model.freeze_nodes(freeze=True)\n",
    "    print(\"3. Nodes frozen\")\n",
    "\n",
    "    # init step\n",
    "    with pxu.step(model, pxc.STATUS.INIT, clear_params=pxc.VodeParam.Cache):\n",
    "        print(\"4. Doing forward for initialization\")\n",
    "        forward(x, model=model)\n",
    "        print(\"5. After forward for initialization\")    \n",
    "\n",
    "    # reinitialise the optimiser state between different batches (NOTE: this is just educational and not needed here because the SGD we use is not-stateful due to lack of momentum)\n",
    "    print(\"6. Reinitialising the optimiser state\")\n",
    "    optim_h.init(pxu.Mask(pxc.VodeParam)(model))\n",
    "    print(\"7. Optimiser state reinitialised\")\n",
    "\n",
    "    print(f\"8. Doing {T} inference steps!\")\n",
    "    for _ in range(T):\n",
    "        with pxu.step(model, clear_params=pxc.VodeParam.Cache):\n",
    "            _, g = pxf.value_and_grad(pxu.Mask(pxu.m(pxc.VodeParam).has_not(frozen=True), [False, True]), has_aux=True)(energy)(model=model)\n",
    "            optim_h.step(model, g[\"model\"], True)\n",
    "\n",
    "    # print that T inference steps have been done\n",
    "    print(\"9. Done with T inference steps!\")\n",
    "        \n",
    "    with pxu.step(model, clear_params=pxc.VodeParam.Cache):\n",
    "        print(\"10. Before computing gradients\")\n",
    "        _, g = pxf.value_and_grad(pxu.Mask(pxnn.LayerParam, [False, True]), has_aux=True)(energy)(model=model)\n",
    "        print(\"7. After computing gradients\")\n",
    "        print(\"Gradient structure:\", g)\n",
    "\n",
    "        print(\"11. Before zeroing out the diagonal gradients\")\n",
    "        # Zero out the diagonal gradients using jax.numpy.fill_diagonal\n",
    "        weight_grads = g[\"model\"].adj_weights.get()\n",
    "        weight_grads = jax.numpy.fill_diagonal(weight_grads, 0.0, inplace=False)\n",
    "        g[\"model\"].adj_weights.set(weight_grads)\n",
    "        print(\"12. After zeroing out the diagonal gradients\")\n",
    "\n",
    "        \n",
    "    print(\"13. Before optimizer step\")\n",
    "    #optim_w.step(model, g[\"model\"])\n",
    "    optim_w.step(model, g[\"model\"], scale_by=1.0/x.shape[0])\n",
    "    print(\"14. After optimizer step\")\n",
    "\n",
    "    with pxu.step(model, clear_params=pxc.VodeParam.Cache):\n",
    "        print(\"15. Before final forward\")\n",
    "        forward(None, model=model)\n",
    "        e_avg_per_sample = model.energy()\n",
    "        print(\"16. After final forward\")\n",
    "\n",
    "    model.freeze_nodes(freeze=False)\n",
    "    print(\"17. Nodes unfrozen\")\n",
    "\n",
    "    return e_avg_per_sample\n",
    "\n",
    "def train(dl, T, *, model: Complete_Graph, optim_w: pxu.Optim, optim_h: pxu.Optim):\n",
    "    e_avg_per_sample_energies = []\n",
    "    for batch in dl:\n",
    "\n",
    "        e_avg_per_sample = train_on_batch(T, batch, model=model, optim_w=optim_w, optim_h=optim_h)\n",
    "        e_avg_per_sample_energies.append(e_avg_per_sample)\n",
    "\n",
    "    W = model.get_W()\n",
    "\n",
    "    # compute epoch energy\n",
    "    epoch_energy = jnp.mean(jnp.array(e_avg_per_sample_energies))\n",
    "    return W, epoch_energy\n",
    "\n",
    "# %%\n",
    "@jit\n",
    "def MAE(W_true, W):\n",
    "    \"\"\"This function returns the Mean Absolute Error for the difference between the true weighted adjacency matrix W_true and th estimated one, W.\"\"\"\n",
    "    MAE_ = jnp.mean(jnp.abs(W - W_true))\n",
    "    return MAE_\n",
    "\n",
    "def compute_binary_adjacency(W, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Compute the binary adjacency matrix by thresholding the input matrix.\n",
    "\n",
    "    Args:\n",
    "    - W (array-like): The weighted adjacency matrix (can be a JAX array or a NumPy array).\n",
    "    - threshold (float): The threshold value to determine the binary matrix. Default is 0.3.\n",
    "\n",
    "    Returns:\n",
    "    - B_est (np.ndarray): The binary adjacency matrix where each element is True if the corresponding \n",
    "                          element in W is greater than the threshold, otherwise False.\n",
    "    \"\"\"\n",
    "    # Convert JAX array to NumPy array if necessary\n",
    "    if isinstance(W, jnp.ndarray):\n",
    "        W = np.array(W)\n",
    "\n",
    "    # Compute the binary adjacency matrix\n",
    "    B_est = np.array(np.abs(W) > threshold)\n",
    "    \n",
    "    return B_est\n",
    "\n",
    "\n",
    "def ensure_DAG(W):\n",
    "    \"\"\"\n",
    "    Ensure that the weighted adjacency matrix corresponds to a DAG.\n",
    "\n",
    "    Inputs:\n",
    "        W: numpy.ndarray - a weighted adjacency matrix representing a directed graph\n",
    "\n",
    "    Outputs:\n",
    "        W: numpy.ndarray - a weighted adjacency matrix without cycles (DAG)\n",
    "    \"\"\"\n",
    "    # Convert the adjacency matrix to a directed graph\n",
    "    g = nx.DiGraph(W)\n",
    "\n",
    "    # Make a copy of the graph to modify\n",
    "    gg = g.copy()\n",
    "\n",
    "    # Remove cycles by removing edges\n",
    "    while not nx.is_directed_acyclic_graph(gg):\n",
    "        h = gg.copy()\n",
    "\n",
    "        # Remove all the sources and sinks\n",
    "        while True:\n",
    "            finished = True\n",
    "\n",
    "            for node, in_degree in nx.in_degree_centrality(h).items():\n",
    "                if in_degree == 0:\n",
    "                    h.remove_node(node)\n",
    "                    finished = False\n",
    "\n",
    "            for node, out_degree in nx.out_degree_centrality(h).items():\n",
    "                if out_degree == 0:\n",
    "                    h.remove_node(node)\n",
    "                    finished = False\n",
    "\n",
    "            if finished:\n",
    "                break\n",
    "\n",
    "        # Find a cycle with a random walk starting at a random node\n",
    "        node = list(h.nodes)[0]\n",
    "        cycle = [node]\n",
    "        while True:\n",
    "            edges = list(h.out_edges(node))\n",
    "            _, node = edges[np.random.choice(len(edges))]\n",
    "\n",
    "            if node in cycle:\n",
    "                break\n",
    "\n",
    "            cycle.append(node)\n",
    "\n",
    "        # Extract the cycle path and adjust it to start at the first occurrence of the repeated node\n",
    "        cycle = np.array(cycle)\n",
    "        i = np.argwhere(cycle == node)[0][0]\n",
    "        cycle = cycle[i:]\n",
    "        cycle = cycle.tolist() + [node]\n",
    "\n",
    "        # Find edges in that cycle\n",
    "        edges = list(zip(cycle[:-1], cycle[1:]))\n",
    "\n",
    "        # Randomly pick an edge to remove\n",
    "        edge = edges[np.random.choice(len(edges))]\n",
    "        gg.remove_edge(*edge)\n",
    "\n",
    "    # Convert the modified graph back to a weighted adjacency matrix\n",
    "    W_acyclic = nx.to_numpy_array(gg)\n",
    "\n",
    "    return W_acyclic\n",
    "\n",
    "# %%\n",
    "# for reference compute the MAE, SID, and SHD between the true adjacency matrix and an all-zero matrix and then print it\n",
    "# this acts as a baseline for the MAE, SID, and SHD similar to how 1/K accuracy acts as a baseline for classification tasks where K is the number of classes\n",
    "W_zero = np.zeros_like(W_true)\n",
    "print(\"MAE between the true adjacency matrix and an all-zero matrix: \", MAE(W_true, W_zero))\n",
    "print(\"SHD between the true adjacency matrix and an all-zero matrix: \", SHD(B_true, compute_binary_adjacency(W_zero)))\n",
    "#print(\"SID between the true adjacency matrix and an all-zero matrix: \", SID(W_true, W_zero))\n",
    "\n",
    "# %%\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n",
    "# This is a simple collate function that stacks numpy arrays used to interface\n",
    "# the PyTorch dataloader with JAX. In the future we hope to provide custom dataloaders\n",
    "# that are independent of PyTorch.\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple, list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "# The dataloader assumes cuda is being used, as such it sets 'pin_memory = True' and\n",
    "# 'prefetch_factor = 2'. Note that the batch size should be constant during training, so\n",
    "# we set 'drop_last = True' to avoid having to deal with variable batch sizes.\n",
    "class TorchDataloader(torch.utils.data.DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=None,\n",
    "        sampler=None,\n",
    "        batch_sampler=None,\n",
    "        num_workers=1,\n",
    "        pin_memory=True,\n",
    "        timeout=0,\n",
    "        worker_init_fn=None,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=2,\n",
    "    ):\n",
    "        super(self.__class__, self).__init__(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            sampler=sampler,\n",
    "            batch_sampler=batch_sampler,\n",
    "            num_workers=num_workers,\n",
    "            collate_fn=numpy_collate,\n",
    "            pin_memory=pin_memory,\n",
    "            drop_last=True if batch_sampler is None else None,\n",
    "            timeout=timeout,\n",
    "            worker_init_fn=worker_init_fn,\n",
    "            persistent_workers=persistent_workers,\n",
    "            prefetch_factor=prefetch_factor,\n",
    "        )\n",
    "\n",
    "\n",
    "# Create the custom dataset\n",
    "dataset = CustomDataset(X)\n",
    "# Create the custom dataset with standardized data\n",
    "dataset_std = CustomDataset(X_std)\n",
    "\n",
    "# Create the dataloader\n",
    "dl = TorchDataloader(dataset, batch_size=batch_size, shuffle=True)\n",
    "######## OR ########\n",
    "#dl = TorchDataloader(dataset_std, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# %%\n",
    "# Initialize the model and optimizers\n",
    "with pxu.step(model, pxc.STATUS.INIT, clear_params=pxc.VodeParam.Cache):\n",
    "    forward(jnp.zeros((batch_size, model.n_nodes.get())), model=model)\n",
    "    optim_h = pxu.Optim(optax.sgd(h_learning_rate), pxu.Mask(pxc.VodeParam)(model))\n",
    "    #optim_w = pxu.Optim(optax.sgd(w_learning_rate), pxu.Mask(pxnn.LayerParam)(model))\n",
    "\n",
    "    \"\"\"\n",
    "    optim_w = pxu.Optim(\n",
    "    optax.chain(\n",
    "        optax.clip_by_global_norm(clip_value),  # Clip gradients by global norm\n",
    "        optax.sgd(w_learning_rate)  # Apply SGD optimizer\n",
    "    ),\n",
    "    pxu.Mask(pxnn.LayerParam)(model)  # Masking the parameters of the model\n",
    ")\n",
    "    \"\"\"\n",
    "    #optim_w = pxu.Optim(optax.adafactor(w_learning_rate), pxu.Mask(pxnn.LayerParam)(model))\n",
    "    #optim_w = pxu.Optim(optax.sgd(w_learning_rate, momentum=0.95), pxu.Mask(pxnn.LayerParam)(model))\n",
    "    #optim_w = pxu.Optim(optax.adamw(w_learning_rate, weight_decay=5e-2), pxu.Mask(pxnn.LayerParam)(model))\n",
    "    #optim_w = pxu.Optim(optax.adamw(w_learning_rate, nesterov=True), pxu.Mask(pxnn.LayerParam)(model))\n",
    "    #optim_w = pxu.Optim(optax.adamw(w_learning_rate, nesterov=False), pxu.Mask(pxnn.LayerParam)(model))\n",
    "    optim_w = pxu.Optim(optax.adam(w_learning_rate), pxu.Mask(pxnn.LayerParam)(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start difference (cont.) between W_true and W_init: 0.9835\n",
      "Start SHD between B_true and B_init: 70.0000\n",
      "The diagonal of the initial W:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Starting train_on_batch\n",
      "2. Model set to train mode\n",
      "3. Nodes frozen\n",
      "4. Doing forward for initialization\n",
      "Forward: Starting\n",
      "The shape of x in __call__ if statement: (10,)\n",
      "The shape of reshaped_x in __call__ if statement: (10, 1)\n",
      "Successfully finished mlp_forward in __call__ for x is not None\n",
      "Forward: Completed\n",
      "5. After forward for initialization\n",
      "6. Reinitialising the optimiser state\n",
      "7. Optimiser state reinitialised\n",
      "8. Doing 64 inference steps!\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42d8c22180>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f3d4c616fc0; to 'JaxprTracer' at 0x7f3d4c617100>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42d8b830d0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42c4a88f80>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42c4b8fc90; to 'JaxprTracer' at 0x7f42c4b8fd30>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42c4ab6bc0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42bbd49900>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42bbd8bb50; to 'JaxprTracer' at 0x7f42bbd8bb00>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42bbd7f430>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42bbd49c30>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42bbda05e0; to 'JaxprTracer' at 0x7f42bbda0590>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42bbd95180>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42bb915590>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42bb960b80; to 'JaxprTracer' at 0x7f42bb960b30>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42bb956230>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42bb9158c0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42bb9615d0; to 'JaxprTracer' at 0x7f42bb961580>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42bb956fb0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b96d5220>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b950de90; to 'JaxprTracer' at 0x7f42b950de40>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b96fb160>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b96d5550>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b950e8e0; to 'JaxprTracer' at 0x7f42b950e890>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b9518e50>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b9278e80>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b92a8a40; to 'JaxprTracer' at 0x7f42b92a89f0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b929e110>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b92791b0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b92a9440; to 'JaxprTracer' at 0x7f42b92a93f0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b929eda0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b6ed8aa0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b6ef38d0; to 'JaxprTracer' at 0x7f42b6ef3880>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b6eebd00>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b6ed8dd0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b6d08360; to 'JaxprTracer' at 0x7f42b6d08310>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b6d04ac0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b6a906d0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b6aa9df0; to 'JaxprTracer' at 0x7f42b6aa9da0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b6aa5b40>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b6a90a10>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b6aaa840; to 'JaxprTracer' at 0x7f42b6aaa7f0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b6aa6920>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b46b82e0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b46c5670; to 'JaxprTracer' at 0x7f42b46c5620>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b46b3970>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b46b8610>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b46c60c0; to 'JaxprTracer' at 0x7f42b46c6070>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b46cc730>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b43b3ec0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b4272890; to 'JaxprTracer' at 0x7f42b4272840>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b4279810>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b4284220>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b42732e0; to 'JaxprTracer' at 0x7f42b4273290>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b427a5f0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b1fc3b20>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b1e774c0; to 'JaxprTracer' at 0x7f42b1e77470>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b1e73640>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b1fc3e60>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b1e77f10; to 'JaxprTracer' at 0x7f42b1e77ec0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b1e84400>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b1b7b790>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b1a30810; to 'JaxprTracer' at 0x7f42b1a307c0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b1a294b0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b1b7bac0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b1a31260; to 'JaxprTracer' at 0x7f42b1a31210>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b1a2a230>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b17833e0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b16252b0; to 'JaxprTracer' at 0x7f42b1625260>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b161b280>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b1783710>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b1625d00; to 'JaxprTracer' at 0x7f42b1625cb0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b16380d0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b131efe0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b13ac1d0; to 'JaxprTracer' at 0x7f42b13ac180>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b13a50f0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b131f310>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b13acc20; to 'JaxprTracer' at 0x7f42b13acbd0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b13a5e70>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b0f42bf0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b0fc7150; to 'JaxprTracer' at 0x7f42b0fc7100>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b0fc2ef0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b0f42f20>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b0fc7ba0; to 'JaxprTracer' at 0x7f42b0fc7b50>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b0fc3c70>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b0b2e7f0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b0ba3830; to 'JaxprTracer' at 0x7f42b0ba37e0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b0b971c0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b0b2eb20>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b0bb82c0; to 'JaxprTracer' at 0x7f42b0bb8270>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b0badae0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b08da3f0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42ae750f90; to 'JaxprTracer' at 0x7f42ae750f40>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42ae746b00>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b08da720>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42ae7519e0; to 'JaxprTracer' at 0x7f42ae751990>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42ae7478e0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42ae4f6000>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42ae361710; to 'JaxprTracer' at 0x7f42ae3616c0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42ae351b70>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42ae4f6330>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42ae362160; to 'JaxprTracer' at 0x7f42ae362110>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42ae365720>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42ae0edc00>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b1f45710; to 'JaxprTracer' at 0x7f42b1f46c00>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b157bca0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42ae0edf30>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42b1f44a90; to 'JaxprTracer' at 0x7f42b1f47f60>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42b155b820>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42adcc5800>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42adb0bdd0; to 'JaxprTracer' at 0x7f42adb0bd80>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42adb02680>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42adcc5b40>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42adb24860; to 'JaxprTracer' at 0x7f42adb24810>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42adb1d360>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42ad8c5430>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42ab708540; to 'JaxprTracer' at 0x7f42ab7084f0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42ab6fa620>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42ad8c5760>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42ab708f90; to 'JaxprTracer' at 0x7f42ab708f40>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42ab6fb3a0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42ab455030>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42b087b740; to 'JaxprTracer' at 0x7f42b0878e50>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42ab46e500>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42ab455360>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42ae363740; to 'JaxprTracer' at 0x7f42ae362ac0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42ab47d240>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42ab094c20>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42ab0b2bb0; to 'JaxprTracer' at 0x7f42ab0b2b60>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42ab0b6050>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42ab094f50>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42ab0b3600; to 'JaxprTracer' at 0x7f42ab0b35b0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42ab0b6dd0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42a4c90820>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42a4ca3290; to 'JaxprTracer' at 0x7f42a4ca3240>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42a4c97e20>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42a4c90b50>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42a4ca3ce0; to 'JaxprTracer' at 0x7f42a4ca3c90>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42a4cb0c40>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42a4888420>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42a4883970; to 'JaxprTracer' at 0x7f42a4883920>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42a488dcc0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42a4888750>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42a489c400; to 'JaxprTracer' at 0x7f42a489c3b0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42a488ea40>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f429de30120>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f429de2d8a0; to 'JaxprTracer' at 0x7f429de2d850>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429de23a90>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f429de30350>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f429de2e2f0; to 'JaxprTracer' at 0x7f429de2e2a0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429de3c8b0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f429db73bf0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f429da2e020; to 'JaxprTracer' at 0x7f429da2dfd0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429da31900>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f429db73f20>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f429da2ea70; to 'JaxprTracer' at 0x7f429da2ea20>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429da32680>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f429b75b7f0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f429b602700; to 'JaxprTracer' at 0x7f429b6026b0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429b5fb6d0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f429b75bb20>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f429b603150; to 'JaxprTracer' at 0x7f429b603100>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429b6184f0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f429deb33f0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f429db52160; to 'JaxprTracer' at 0x7f429db53150>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429b375510>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f429deb3720>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f429db7c5e0; to 'JaxprTracer' at 0x7f429db7d5d0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429b376200>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4298f22ff0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4298fb5620; to 'JaxprTracer' at 0x7f4298fb55d0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4298faf340>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4298f23320>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4298fb6070; to 'JaxprTracer' at 0x7f4298fb6020>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4298fc0100>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f429861abf0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42986a5cb0; to 'JaxprTracer' at 0x7f42986a5c60>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42986a9150>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f429861af20>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42986a6750; to 'JaxprTracer' at 0x7f42986a66b0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42986a9f00>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42982127f0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f429828a3e0; to 'JaxprTracer' at 0x7f429828a390>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4298286f80>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4298212b20>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f429828ae30; to 'JaxprTracer' at 0x7f429828ade0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4298287d00>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4295e023f0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4295e6aac0; to 'JaxprTracer' at 0x7f4295e6aa70>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4295e5f250>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4295e02720>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4295e6b510; to 'JaxprTracer' at 0x7f4295e6b4c0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4295e71b70>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4295ba1ff0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4295a0d210; to 'JaxprTracer' at 0x7f4295a0d1c0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4295a02b90>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4295ba2320>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4295a0dc60; to 'JaxprTracer' at 0x7f4295a0dc10>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4295a03970>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42957b1bf0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4295609990; to 'JaxprTracer' at 0x7f4295609940>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42955f6ec0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42957b1f20>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f429560a3e0; to 'JaxprTracer' at 0x7f429560a390>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429560d780>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42953957f0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42953de070; to 'JaxprTracer' at 0x7f42953de020>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42953d67d0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4295395b20>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42953deac0; to 'JaxprTracer' at 0x7f42953dea70>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42953d75b0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4292f7d3f0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4292fb67a0; to 'JaxprTracer' at 0x7f4292fb6750>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4292faa6e0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4292f7d720>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4292fb71f0; to 'JaxprTracer' at 0x7f4292fb71a0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4292fbd3c0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4292b0cff0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4295609a80; to 'JaxprTracer' at 0x7f4295609530>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4292b32440>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4292b0d320>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f429560b010; to 'JaxprTracer' at 0x7f429560ad90>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4292b331c0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4290740bf0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4290761e40; to 'JaxprTracer' at 0x7f4290761df0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42907532e0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4290740f20>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4290762890; to 'JaxprTracer' at 0x7f4290762840>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4290769030>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4290340800>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42903525c0; to 'JaxprTracer' at 0x7f4290352570>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429034e080>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4290340b30>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4290352fc0; to 'JaxprTracer' at 0x7f4290352f70>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f429034ee00>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4289f30400>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4289f36d40; to 'JaxprTracer' at 0x7f4289f36cf0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4289f2bfa0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4289f30740>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4289f376a0; to 'JaxprTracer' at 0x7f4289f37650>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4289f40e50>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4289b18100>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4289b072e0; to 'JaxprTracer' at 0x7f4289b07290>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4289b11cc0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4289b18330>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4289b07d30; to 'JaxprTracer' at 0x7f4289b07ce0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4289b12a40>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42899dbbe0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4290001260; to 'JaxprTracer' at 0x7f4290001170>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4289867ac0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42899dbf10>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42898809a0; to 'JaxprTracer' at 0x7f4289880950>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f428987c880>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42873f37e0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f428749a980; to 'JaxprTracer' at 0x7f428749a930>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42874a18d0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42873f3b10>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f428749b3d0; to 'JaxprTracer' at 0x7f428749b380>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42874a26b0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4286fef400>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f428708b100; to 'JaxprTracer' at 0x7f428708b0b0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4287087700>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4286fef730>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f428708bb50; to 'JaxprTracer' at 0x7f428708bb00>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42870984c0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4286de3000>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4286c778d0; to 'JaxprTracer' at 0x7f4286c77880>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4286c7d660>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4286de3360>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4286c88270; to 'JaxprTracer' at 0x7f4286c88220>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4286c7e4d0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42869dac40>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f428685ff10; to 'JaxprTracer' at 0x7f428685fec0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4286863340>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42869daf70>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42868709a0; to 'JaxprTracer' at 0x7f4286870950>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4286878100>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42865d2840>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f428644e890; to 'JaxprTracer' at 0x7f428644e840>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4286451150>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42865d2b70>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f428644f2e0; to 'JaxprTracer' at 0x7f428644f290>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4286451f30>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f428619a450>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42a0717600; to 'JaxprTracer' at 0x7f42a07175b0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42a0712fb0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f428619a780>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42a0728090; to 'JaxprTracer' at 0x7f42a0728040>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42a0713d30>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42a04a2050>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42a0303d30; to 'JaxprTracer' at 0x7f42a0303ce0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42a02f9fc0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42a04a2380>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42a03187c0; to 'JaxprTracer' at 0x7f42a0318770>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42a0311b70>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4281f8dc50>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4281dec450; to 'JaxprTracer' at 0x7f4281dec400>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4281fdebc0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4281f8df80>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4281decef0; to 'JaxprTracer' at 0x7f4281decea0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4281fdf970>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4281b71860>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4281bc4bd0; to 'JaxprTracer' at 0x7f4281bc4b80>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4281baaef0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4281b71b90>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4281bc5620; to 'JaxprTracer' at 0x7f4281bc55d0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4281bc17b0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f427f759470>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f427f78f560; to 'JaxprTracer' at 0x7f427f78f510>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f427f792800>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f427f7597a0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f427f78ffb0; to 'JaxprTracer' at 0x7f427f78ff60>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f427f7935e0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f427f349080>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f427f380540; to 'JaxprTracer' at 0x7f427f3804f0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f427f366710>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f427f3493b0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f427f380f90; to 'JaxprTracer' at 0x7f427f380f40>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f427f37d3f0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42782fcc80>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4278321210; to 'JaxprTracer' at 0x7f42783211c0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f427831a440>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42782fcfb0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4278321c60; to 'JaxprTracer' at 0x7f4278321c10>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f427831b220>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4275f10880>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4275f25940; to 'JaxprTracer' at 0x7f4275f258f0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4275f17340>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4275f10bb0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4275f26390; to 'JaxprTracer' at 0x7f4275f26340>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4275f2d030>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4275af0480>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4275b02020; to 'JaxprTracer' at 0x7f4275b01fd0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4275afe080>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4275af07b0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4275b02a70; to 'JaxprTracer' at 0x7f4275b02a20>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4275afee60>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42758dc080>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42758ce7a0; to 'JaxprTracer' at 0x7f42758ce750>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42758c7eb0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42758dc3b0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42758cf1f0; to 'JaxprTracer' at 0x7f42758cf1a0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42736e4c70>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4273407c50>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f42734bd1c0; to 'JaxprTracer' at 0x7f42734bd170>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42734b5d50>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4273407f80>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f42734bdc10; to 'JaxprTracer' at 0x7f42734bdbc0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42734b6ad0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4272ff7850>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f427309a110; to 'JaxprTracer' at 0x7f427309a0c0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4273093b50>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4272ff7b80>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f427309ab60; to 'JaxprTracer' at 0x7f427309ab10>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42730a4910>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f427835b450>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f427f4a2340; to 'JaxprTracer' at 0x7f427f4a2200>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4298b29960>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f427835b780>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f427f4d07c0; to 'JaxprTracer' at 0x7f427f4d0680>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4298b2a740>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4270ea3050>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4270d37ce0; to 'JaxprTracer' at 0x7f4270d37c90>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4270d2f760>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4270ea3390>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4270d48770; to 'JaxprTracer' at 0x7f4270d48720>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4270d44580>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4270aa6c60>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4270934450; to 'JaxprTracer' at 0x7f4270934400>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f427092d5d0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4270aa6f90>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4270934ea0; to 'JaxprTracer' at 0x7f4270934e50>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f427092e350>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f426c69e870>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f426c51cb30; to 'JaxprTracer' at 0x7f426c51cae0>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f426c5133a0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f426c69eba0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f426c51d580; to 'JaxprTracer' at 0x7f426c51d530>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f426c5241c0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f426c292470>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f426c1092b0; to 'JaxprTracer' at 0x7f426c109260>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f426c105210>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f426c2927a0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f426c109d00; to 'JaxprTracer' at 0x7f426c109cb0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f426c105f90>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "9. Done with T inference steps!\n",
      "10. Before computing gradients\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=4/0)> with\n",
      "  val = Traced<ShapedArray(float32[128])>with<JVPTrace(level=3/0)> with\n",
      "    primal = Traced<ShapedArray(float32[128])>with<DynamicJaxprTrace(level=1/0)>\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=2/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4269c34ad0>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4269c47290; to 'JaxprTracer' at 0x7f4269c47240>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4269c4e020>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4269c34e80>, in_tracers=(Traced<ShapedArray(float32[10,10]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4269c47c40; to 'JaxprTracer' at 0x7f4269c47d30>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[10,10]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4269c4eda0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: DAG constraint term: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4269b2dd50>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>,), out_tracer_refs=[<weakref at 0x7f4269ae86d0; to 'JaxprTracer' at 0x7f4269ae8400>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'subtract', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4269b95210>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Final objective: Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with\n",
      "  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f4269b2e200>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x7f4269ae92b0; to 'JaxprTracer' at 0x7f4269ae8c20>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m b\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f4269b96d10>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "7. After computing gradients\n",
      "Gradient structure: {'__RKG': (RandomKeyGenerator):, 'model': (Complete_Graph):\n",
      "  .mlp_layers[0][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .adj_weights: LayerParam([10,10], float32)}\n",
      "11. Before zeroing out the diagonal gradients\n",
      "12. After zeroing out the diagonal gradients\n",
      "13. Before optimizer step\n",
      "14. After optimizer step\n",
      "15. Before final forward\n",
      "Forward: Starting\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Forward: Completed\n",
      "16. After final forward\n",
      "17. Nodes unfrozen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MAE 0.3001, SHD 21.0000 || Energy 11.0809: 100%|██████████| 2000/2000 [16:38<00:00,  2.00it/s]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An epoch (with compiling and testing) took on average: 0.4991 seconds\n",
      "The diagonal of the final W:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(Complete_Graph):\n",
      "  .has_bias: True\n",
      "  .mlp_layers[0][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_vodes[0][0].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[0][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][1].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[0][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][2].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[0][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][3].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[0][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][4].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[0][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][5].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[0][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][6].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[0][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][7].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[0][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][8].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[0][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[0][9].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[0][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][0].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[1][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][1].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[1][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][2].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[1][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][3].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[1][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][4].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[1][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][5].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[1][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][6].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[1][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][7].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[1][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][8].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[1][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[1][9].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[1][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][0].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[2][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][1].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[2][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][2].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[2][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][3].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[2][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][4].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[2][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][5].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[2][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][6].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[2][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][7].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[2][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][8].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[2][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[2][9].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[2][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][0].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[3][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][1].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[3][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][2].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[3][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][3].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[3][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][4].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[3][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][5].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[3][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][6].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[3][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][7].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[3][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][8].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[3][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[3][9].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[3][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][0].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[4][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][1].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[4][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][2].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[4][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][3].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[4][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][4].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[4][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][5].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[4][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][6].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[4][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][7].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[4][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][8].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[4][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[4][9].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[4][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][0].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[5][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][1].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[5][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][2].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[5][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][3].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[5][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][4].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[5][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][5].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[5][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][6].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[5][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][7].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[5][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][8].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[5][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[5][9].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[5][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][0].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[6][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][1].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[6][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][2].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[6][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][3].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[6][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][4].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[6][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][5].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[6][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][6].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[6][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][7].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[6][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][8].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[6][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[6][9].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[6][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][0].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[7][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][1].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[7][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][2].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[7][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][3].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[7][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][4].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[7][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][5].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[7][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][6].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[7][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][7].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[7][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][8].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[7][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[7][9].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[7][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][0].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[8][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][1].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[8][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][2].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[8][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][3].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[8][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][4].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[8][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][5].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[8][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][6].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[8][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][7].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[8][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][8].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[8][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[8][9].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[8][9].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][0].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[9][0].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][1].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[9][1].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][2].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[9][2].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][3].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[9][3].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][4].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[9][4].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][5].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[9][5].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][6].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[9][6].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][7].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[9][7].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][8].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[9][8].cache: Cache(params=None)\n",
      "  .mlp_vodes[9][9].h: VodeParam([128,3], float32)\n",
      "  .mlp_vodes[9][9].cache: Cache(params=None)\n",
      "  .adj_weights: LayerParam([10,10], float32)\n",
      "  .vodes[0].h: VodeParam([128,10,1], float32)\n",
      "  .vodes[0].cache: Cache(params=None)\n",
      "\n",
      "Energy: Starting computation\n",
      "The shape of x_ in __call__ else statement: (10, 1)\n",
      "The shape of reshaped_x_ in __call__ else statement: (10, 1)\n",
      "Energy: Got model output\n",
      "Energy: Got W (shape: (10, 10)) and d: 10\n",
      "Energy: PC energy term: Traced<ShapedArray(float32[])>with<BatchTrace(level=3/0)> with\n",
      "  val = Traced<ConcreteArray([19.313307    1.717802   15.023878    5.4121633   5.319829    2.1735995\n",
      "  1.0161029  10.267639    6.3911905  24.181517    6.636482    1.1444274\n",
      " 15.977912    0.20579335  6.0932164  20.44841    11.366626    4.8647375\n",
      " 14.391559    0.3377321   3.3862433   2.804945   23.102112    1.0193362\n",
      " 15.801745   36.159603    6.1724176   0.67451674 33.602493   30.093552\n",
      " 10.38459     0.42691728  6.853815   12.767071    4.622837   21.130014\n",
      "  3.5015478   8.678494   16.450623   10.487506    0.16142558  4.158205\n",
      " 21.24319     1.6172664   5.419168    0.05500486  0.82587737 13.67733\n",
      " 21.5041     10.931244   47.08318    19.271873    0.07721986 13.8294735\n",
      " 16.69221     4.993537   23.241112   30.609955    0.06346627 13.203498\n",
      "  4.926134   28.533865   32.398567    5.471249   39.204792   13.259157\n",
      "  9.1193      5.4324446  23.31149    10.977273    3.4488747  25.65095\n",
      "  0.25605735 18.715757    0.21101964  8.304207    0.7127455   8.767208\n",
      "  2.7846148  10.262183    3.5272303   2.1408963  10.682002   13.629025\n",
      "  2.1291559   8.623134   31.415407    2.0424662   2.9756594   8.821522\n",
      " 26.487854    9.301374   11.45002     3.9386497  13.61875    24.6425\n",
      " 11.13399     7.4782367   0.16586035 20.985334    3.7278643  15.44825\n",
      "  1.2845156   0.8544778  15.42729    18.68755    27.234386   13.462458\n",
      "  0.07500646 24.016512    1.5344155   5.9825172  18.656391   11.605818\n",
      " 29.359474    0.36819008 24.741879    2.450927    4.575789    1.0081123\n",
      " 20.783005    9.200628   21.34426    10.027268    7.279793    7.4570465\n",
      "  3.5930693   1.8248211 ], dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "    primal = Array([19.313307  ,  1.717802  , 15.023878  ,  5.4121633 ,  5.319829  ,\n",
      "        2.1735995 ,  1.0161029 , 10.267639  ,  6.3911905 , 24.181517  ,\n",
      "        6.636482  ,  1.1444274 , 15.977912  ,  0.20579335,  6.0932164 ,\n",
      "       20.44841   , 11.366626  ,  4.8647375 , 14.391559  ,  0.3377321 ,\n",
      "        3.3862433 ,  2.804945  , 23.102112  ,  1.0193362 , 15.801745  ,\n",
      "       36.159603  ,  6.1724176 ,  0.67451674, 33.602493  , 30.093552  ,\n",
      "       10.38459   ,  0.42691728,  6.853815  , 12.767071  ,  4.622837  ,\n",
      "       21.130014  ,  3.5015478 ,  8.678494  , 16.450623  , 10.487506  ,\n",
      "        0.16142558,  4.158205  , 21.24319   ,  1.6172664 ,  5.419168  ,\n",
      "        0.05500486,  0.82587737, 13.67733   , 21.5041    , 10.931244  ,\n",
      "       47.08318   , 19.271873  ,  0.07721986, 13.8294735 , 16.69221   ,\n",
      "        4.993537  , 23.241112  , 30.609955  ,  0.06346627, 13.203498  ,\n",
      "        4.926134  , 28.533865  , 32.398567  ,  5.471249  , 39.204792  ,\n",
      "       13.259157  ,  9.1193    ,  5.4324446 , 23.31149   , 10.977273  ,\n",
      "        3.4488747 , 25.65095   ,  0.25605735, 18.715757  ,  0.21101964,\n",
      "        8.304207  ,  0.7127455 ,  8.767208  ,  2.7846148 , 10.262183  ,\n",
      "        3.5272303 ,  2.1408963 , 10.682002  , 13.629025  ,  2.1291559 ,\n",
      "        8.623134  , 31.415407  ,  2.0424662 ,  2.9756594 ,  8.821522  ,\n",
      "       26.487854  ,  9.301374  , 11.45002   ,  3.9386497 , 13.61875   ,\n",
      "       24.6425    , 11.13399   ,  7.4782367 ,  0.16586035, 20.985334  ,\n",
      "        3.7278643 , 15.44825   ,  1.2845156 ,  0.8544778 , 15.42729   ,\n",
      "       18.68755   , 27.234386  , 13.462458  ,  0.07500646, 24.016512  ,\n",
      "        1.5344155 ,  5.9825172 , 18.656391  , 11.605818  , 29.359474  ,\n",
      "        0.36819008, 24.741879  ,  2.450927  ,  4.575789  ,  1.0081123 ,\n",
      "       20.783005  ,  9.200628  , 21.34426   , 10.027268  ,  7.279793  ,\n",
      "        7.4570465 ,  3.5930693 ,  1.8248211 ], dtype=float32)\n",
      "    tangent = Traced<ShapedArray(float32[128])>with<JaxprTrace(level=1/0)> with\n",
      "      pval = (ShapedArray(float32[128]), None)\n",
      "      recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b47ea930>, in_tracers=(Traced<ShapedArray(float32[128]):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=1/0)>), out_tracer_refs=[<weakref at 0x7f42bb9624d0; to 'JaxprTracer' at 0x7f42bb962d40>], out_avals=[ShapedArray(float32[128])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[128]\u001b[39m b\u001b[35m:f32[128]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[128]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42a493e5c0>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "  batch_dim = 0\n",
      "Energy: L1 reg term: Traced<ConcreteArray(4.83494758605957, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(4.8349476, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b47eb890>, in_tracers=(Traced<ShapedArray(float32[10,10]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x7f42bb9634c0; to 'JaxprTracer' at 0x7f42bb962980>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[10,10]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m b\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0, 1)] a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(b,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': '_reduce_sum', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42a493fd90>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: DAG constraint term: Traced<ConcreteArray(0.00048065185546875, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(0.00048065, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42b6f3d1c0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=1/0)>,), out_tracer_refs=[<weakref at 0x7f42c4951f30; to 'JaxprTracer' at 0x7f42c4951850>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(a,) }, 'in_shardings': (UnspecifiedValue,), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None,), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False,), 'name': 'subtract', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f426703fc10>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "Energy: Final objective: Traced<ConcreteArray(11.287618637084961, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = Array(11.287619, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f42bbfac360>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=1/0)>), out_tracer_refs=[<weakref at 0x7f42c49523e0; to 'JaxprTracer' at 0x7f42c4951260>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m b\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[]\u001b[39m = add a b \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'in_layouts': (None, None), 'out_layouts': (None,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'add', 'keep_unused': False, 'inline': True}, effects=set(), source_info=<jax._src.source_info_util.SourceInfo object at 0x7f42bbf49960>, ctx=JaxprEqnContext(compute_type=None,threefry_partitionable=False))\n",
      "(Complete_Graph):\n",
      "  .mlp_layers[0][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[0][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[0][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[0][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[0][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[1][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[1][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[1][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[1][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[2][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[2][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[2][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[2][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[3][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[3][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[3][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[3][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[4][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[4][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[4][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[4][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[5][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[5][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[5][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[5][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[6][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[6][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[6][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[6][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[7][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[7][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[7][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[7][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[8][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[8][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[8][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[8][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][0][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][0][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][0][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][0][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][1][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][1][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][1][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][1][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][2][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][2][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][2][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][2][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][3][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][3][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][3][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][3][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][4][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][4][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][4][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][4][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][5][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][5][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][5][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][5][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][6][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][6][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][6][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][6][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][7][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][7][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][7][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][7][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][8][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][8][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][8][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][8][1].nn.bias: LayerParam([1], float32)\n",
      "  .mlp_layers[9][9][0].nn.weight: LayerParam([3,1], float32)\n",
      "  .mlp_layers[9][9][0].nn.bias: LayerParam([3], float32)\n",
      "  .mlp_layers[9][9][1].nn.weight: LayerParam([1,3], float32)\n",
      "  .mlp_layers[9][9][1].nn.bias: LayerParam([1], float32)\n",
      "  .adj_weights: LayerParam([10,10], float32)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store differences and energies\n",
    "MAEs = []\n",
    "SHDs = []\n",
    "energies = []\n",
    "\n",
    "# Calculate the initial MAE, SID, and SHD\n",
    "MAE_init = MAE(W_true, model.get_W())\n",
    "print(f\"Start difference (cont.) between W_true and W_init: {MAE_init:.4f}\")\n",
    "\n",
    "SHD_init = SHD(B_true, compute_binary_adjacency(model.get_W()))\n",
    "print(f\"Start SHD between B_true and B_init: {SHD_init:.4f}\")\n",
    "\n",
    "# print the values of the diagonal of the initial W\n",
    "print(\"The diagonal of the initial W: \", jnp.diag(model.get_W()))\n",
    "\n",
    "# Start timing\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Training loop\n",
    "with tqdm(range(nm_epochs), position=0, leave=True) as pbar:\n",
    "    for epoch in pbar:\n",
    "        # Train for one epoch using the dataloader\n",
    "        W, epoch_energy = train(dl, T=T, model=model, optim_w=optim_w, optim_h=optim_h)\n",
    "        \n",
    "        # Calculate the metrics and store them\n",
    "        W = np.array(W)\n",
    "        MAEs.append(float(MAE(W_true, W)))\n",
    "        SHDs.append(float(SHD(B_true, compute_binary_adjacency(W))))\n",
    "        energies.append(float(epoch_energy))\n",
    "        \n",
    "        # Update progress bar with the current status\n",
    "        pbar.set_description(f\"MAE {MAEs[-1]:.4f}, SHD {SHDs[-1]:.4f} || Energy {energies[-1]:.4f}\")\n",
    "\n",
    "# End timing\n",
    "end_time = timeit.default_timer()\n",
    "\n",
    "# Print the average time per epoch\n",
    "average_time_per_epoch = (end_time - start_time) / nm_epochs\n",
    "print(f\"An epoch (with compiling and testing) took on average: {average_time_per_epoch:.4f} seconds\")\n",
    "# print the values of the diagonal of the final W\n",
    "print(\"The diagonal of the final W: \", jnp.diag(model.get_W()))\n",
    "\n",
    "# %%\n",
    "print(model)\n",
    "print()\n",
    "with pxu.step(model, clear_params=pxc.VodeParam.Cache):\n",
    "    _, g = pxf.value_and_grad(pxu.Mask(pxnn.LayerParam, [False, True]), has_aux=True)(energy)(model=model)\n",
    "    print(g[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Set the style and color palette\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"tab10\")\n",
    "\n",
    "# Create a figure and axis with a 1x3 layout for side-by-side plots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))  # Adjusting layout to 1 row and 3 columns\n",
    "fig.suptitle('Performance Metrics Over Epochs', fontsize=16, weight='bold')\n",
    "\n",
    "# Plot the MAE\n",
    "sns.lineplot(x=range(len(MAEs)), y=MAEs, ax=axs[0], color=palette[0])\n",
    "axs[0].set_title(\"Mean Absolute Error (MAE)\", fontsize=14)\n",
    "axs[0].set_xlabel(\"Epoch\", fontsize=12)\n",
    "axs[0].set_ylabel(\"MAE\", fontsize=12)\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot the SHD\n",
    "sns.lineplot(x=range(len(SHDs)), y=SHDs, ax=axs[1], color=palette[2])\n",
    "axs[1].set_title(\"Structural Hamming Distance (SHD)\", fontsize=14)\n",
    "axs[1].set_xlabel(\"Epoch\", fontsize=12)\n",
    "axs[1].set_ylabel(\"SHD\", fontsize=12)\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot the Energy\n",
    "sns.lineplot(x=range(len(energies)), y=energies, ax=axs[2], color=palette[3])\n",
    "axs[2].set_title(\"Energy\", fontsize=14)\n",
    "axs[2].set_xlabel(\"Epoch\", fontsize=12)\n",
    "axs[2].set_ylabel(\"Energy\", fontsize=12)\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Improve layout and show the plot\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to fit the suptitle\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Is the estimated binary adjacency matrix a DAG? True\n",
      "The h_reg term for the true weighted adjacency matrix W_true is: 0.0000\n",
      "The h_reg term for the estimated weighted adjacency matrix W_est is: 0.0005\n",
      "The h_reg term for the fixed weighted adjacency matrix W_fix is: 0.0000\n",
      "The first 5 rows and columns of the estimated weighted adjacency matrix W_est\n",
      "[[ 0.      0.0247 -0.0474 -0.0001  0.    ]\n",
      " [-0.0564  0.      0.084   0.007   0.0105]\n",
      " [-0.1555  0.0128  0.      0.1414  0.    ]\n",
      " [ 0.0921  0.2172 -0.0456  0.      0.1426]\n",
      " [-0.2134 -0.0001  0.0266  0.0066  0.    ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "30.0\n",
      "20.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp0AAAEnCAYAAADrbPiwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8SUlEQVR4nO3de1gUZd8H8O9CooLuEobkKTf0WlJDETMjjNTySdLKPIV2IDXDN/JAdhV2sHzVInqsFCrLQxJ56GCWHfDR7EBB2cE08zFTNkozyVR2Qc4w7x9d7Nu6C8zs7OzO7Hw/17WXcu/M7H0z7tffnA2CIAggIiIiIlJQkL87QERERESBj0UnERERESmORScRERERKY5FJxEREREpjkUnERERESmORScRERERKY5FJxEREREpjkUnERERESmORScRERERKY5FJ2leZmYmBg8e7O9uEBEFlJiYGPzv//6vv7tBAYRFp87s2bMHOTk5sNvt/u4KEZGimHdE6sKiU2e+//575ObmMoSJKOAx74jUhUUn+URDQwPq6ur83Q0iIhdNTU2ora31dzc8UlVV5e8uEInGolNDysrKsHDhQlx55ZW49NJLMXbsWLz11ltO0+Tn52Ps2LEYNGgQhg4digkTJuC9994DAOTk5CA7OxsAcM011yAmJgYxMTE4duyY6D4UFBTg+uuvR2xsLMaNG4edO3ciMzMTo0aNckxz7NgxxMTEYO3atVi/fj2uvfZaxMbGoqSkBHV1dVixYgUmTJiAIUOGIC4uDtOmTcNXX33l9DnnLmPkyJEYOHAgbrvtNvz8888t/n7uueceDB48GFdccQWeeuopNDY2ih4bEQWO1vKu+VzFbdu2YezYsYiNjcXnn3+O3bt3IyYmBrt373ZaVvM8b7/9tlN7SUkJ5s6di8svvxyxsbGYMGECdu3aJbmvNTU1WLp0KYYNG4bBgwdj9uzZKCsrQ0xMDHJycpzGFBMTgyNHjmDBggUYOnQopk2bBgD46aefkJmZiWuuuQaxsbFITEzEwoULcebMGZffS0xMDEpKSjBv3jzEx8dj2LBhWLp0aYuF90cffYRx48Y5/t8pLCyUPEYiADjP3x0gcf766y9MmTIFBoMBt956KyIiIlBYWIiHH34YlZWVuPPOO/HGG29g6dKluO6663DHHXegtrYWhw4dwr59+3DDDTdg9OjRKC0txfvvv4+FCxfi/PPPBwBERESI6sOnn36KjIwMWCwWLFiwADabDQ8//DCioqLcTv/222+jtrYWU6ZMQUhICEwmEyorK/Hmm29i3LhxmDx5Ms6ePYu33noLd911F958803069fPaRnvvPMOzp49i2nTpqG2thb5+flITU3Fe++9hwsuuMAxXWNjI2bOnImBAwfigQcewJdffol169ahV69ejlAmIv1oK++++uorFBQU4NZbb8X555+PHj16SDoMf/jwYUydOhVRUVGYNWsWQkNDUVBQgPT0dOTk5GD06NGil5WZmYmCggLcdNNNGDRoEL755hvcfffdLU4/b9489O7dGxkZGRAEAQBQXFyMo0ePYsKECYiMjMThw4fxxhtv4MiRI3jjjTdgMBicljF//nz06NEDCxYswN69e5Gfnw+73e4o1Jt999132LFjB6ZNm4awsDDk5+dj7ty5+OSTTxy/UyLRBNKEhx56SEhMTBROnz7t1J6RkSEMGTJEqK6uFv7nf/5HGDt2bKvLWbNmjWCxWISjR49K7sO4ceOEpKQkobKy0tG2e/duwWKxCCNHjnS0HT16VLBYLEJ8fLxw6tQpp2U0NDQItbW1Tm02m0248sorhYULF7osY+DAgcKJEycc7fv27RMsFovwxBNPONoefPBBwWKxCLm5uU7LHT9+vHDzzTdLHicRBYaW8s5isQiXXHKJcPjwYaf2r776SrBYLMJXX33l1N6cR1u2bHG0paamCuPGjXPKs6amJuGWW24R/vWvf4nu448//ihYLBZh2bJlTu2ZmZmCxWIRVq5c6WhbuXKlYLFYhPvuu89lOdXV1S5t77//vmCxWIRvvvnGZRmzZ892mvbxxx8XLBaLcPDgQUebxWIRBgwYIPz666+OtoMHDwoWi0XIz88XPUaiZjy8rgGCIGDHjh0YNWoUBEHA6dOnHa/hw4ejoqICBw4cgNFoxIkTJ/DDDz94vQ9lZWX4+eefMX78eISFhTnaL7/8clgsFrfz/Otf/3LZixocHIyQkBAAf59HVV5ejoaGBlx66aX473//67KMa6+91mlP6sCBAzFo0CB89tlnLtNOnTrV6echQ4ZIOnWAiPRj6NCh6Nu3r0fzlpeX46uvvkJycjIqKysdeXzmzBkMHz4cpaWlKCsrE7Wszz//HABcjsjcdtttLc6TkpLi0tahQwfH32tra3H69GkMGjQIAHDgwAGX6W+99Va3n3fuofMrr7wSF110kePnSy65BJ06dcLRo0db7B9RS3h4XQNOnz4Nu92O119/Ha+//nqL08yaNQvFxcWYPHkyevfujcTERIwbNw5DhgyR3Yfjx48DgFP4NOvdu7fbgrFnz55ul7V161asW7cOv/zyC+rr61udvnfv3i5tZrMZBQUFTm3t27d3KXBNJhNsNpvbPhCRvrWUT2L89ttvEAQBK1aswIoVK9xOc+rUqRZPPfqn48ePIygoyKU/7rKvmbu+l5eXIzc3Fx9++CFOnTrl9F5FRYXL9Ocu/6KLLkJQUJDLhnq3bt1c5jWZTLwjAHmERacGNDU1AQBuvPFG3HzzzW6niYmJQZcuXbB9+3Z8+umn+Pzzz7Fjxw5s3LgR6enpmDt3ri+7DMB5y7vZu+++i8zMTFx77bWYOXMmunTpguDgYLz00kuytpyDg4PldJWIdMZdPp173mOz5gw+9+cZM2bgqquucjuPuw10b2nfvr1L2/z58/H9999j5syZ6NevH0JDQ9HU1IS77rrLcd5na1oae0vZKmaZROdi0akBERERCAsLQ1NTE6688spWpw0NDcX111+P66+/HnV1dZgzZw5WrVqFtLQ0tG/fvsVgaUv37t0B/L2Ff65ff/1V9HL+85//oFevXsjNzXXqy8qVK91O727ZpaWl6NGjh+jPJCJ9kpp3RqMRgOuewd9//93p5169egEA2rVr12Ymt6V79+5oamrCsWPHYDabHe1SctVms+HLL7/EnDlzcO+99zraS0tLW5zn119/dYyj+eempiZZe4CJ2sJzOjUgODgY1113Hf7zn/+4vV3Q6dOnAcDl1hghISHo06cPBEFwHMbu2LEjAPeHW1oTFRUFi8XiuJq82ddff93iLYxaGgvgvJW8b98+7N271+30H330kdO5UT/88AP27duHpKQkSf0nIv2Rmnc9evRAcHAwvvnmG6f2TZs2Of3cpUsXXH755Xj99dfx559/uiynOZPFGD58OABg48aNTu2vvfaa6GW0tDcyLy+vxXk2bNjg9vOYraQk7unUiAULFmD37t2YMmUKJk+ejL59+8Jms+HAgQP48ssv8fXXX2PmzJm44IILEB8fjy5dusBqteK1117D1VdfjU6dOgEABgwYAAB49tlncf3116Ndu3YYOXIkQkND2+xDRkYG7rnnHkydOhUTJkyA3W7Hhg0bYLFYnArR1owYMQI7duxAeno6RowYgWPHjmHz5s3o27ev25scX3TRRZg6dSqmTp2Kuro6vPrqqwgPD8ddd90l4bdHRHrUUt61pHPnzhgzZgxee+01GAwG9OrVC59++qnLOZIA8Nhjj2HatGm44YYbMGXKFPTq1Qt//fUX9u7dixMnTmDbtm2i+njppZfiuuuuQ15eHsrLyx23TGreSylmb22nTp0wdOhQrFmzBvX19YiKikJRUVGrF1IeO3YMs2fPxlVXXYW9e/di27ZtGDduHC655BJR/SbyBItOjbjgggvw5ptv4vnnn8fOnTuxadMmhIeHo2/fvrj//vsBALfccgvee+89vPLKK6iqqsKFF16I22+/Hffcc49jOQMHDsS8efOwefNmfP7552hqasKuXbtEFZ2jRo3CM888g5ycHCxfvhxmsxlPPvkk3nnnHRw+fFjUOCZMmIC//voLr7/+Or744gv07dsXTz/9NLZv346vv/7aZfrx48cjKCgIeXl5OHXqFAYOHIhHH30UXbt2FfmbIyK9ainvWvPII4+goaEBmzdvRkhICMaMGYMHHngA48aNc5qub9++2LJlC3Jzc7F161aUl5cjIiIC/fv3R3p6uqR+PvXUU7jgggvwwQcfYOfOnbjyyivx7LPPYsyYMY67fbRl+fLlWLJkCTZu3AhBEJCYmIjVq1e3eM7pc889hxUrVmD58uU477zzcNttt+GBBx6Q1G8iqQwCzwYmmW666SZERETglVde8doyjx07hmuuuQYPPPAAZs6c6bXlknb9+uuvWLt2Lfbt24fDhw8jOjoa77//fpvzCYKA1atXY+PGjTh9+jT69euHhQsXIi4uTvlOE3no4MGDGD9+PJ5++mnceOONXltuTk4OcnNz8eWXX4p+MAgFDn/nKM/pJNHq6+vR0NDg1LZ792789NNPuPzyy/3UK9KLw4cP47PPPkPv3r3Rp08f0fOtXr0aK1euxJ133omXXnoJkZGRmDFjBu8zSKpRU1Pj0paXl4egoCAMHTrUDz2iQOXvHOXhdUJFRYXb0PunyMhIlJWVYfr06bjxxhvRtWtXWK1WbN68GZGRkW5vVkzkTaNGjcK1114L4O/HBv74449tzlNbW4uXXnoJM2bMwJ133gng74cGjBkzBmvXrsXjjz+uYI9J706ePNnq+x06dEDnzp2xZs0a/Pjjj7jiiisQHByMwsJCFBYW4pZbbnF7n0wiT/k7R1l0EpYtW4atW7e2Os2hQ4dgMpkwYMAAvPnmmzh9+jRCQ0Nx9dVX4/777+czeElxQUHSD8zs2bMHlZWVSE5OdrSFhIRg9OjR2Llzpze7R+Si+cr0ltx8883IysrC4MGDUVRUhBdeeAFVVVXo1q0b5syZg9mzZ/uop6QX/s5RFp2Eu+66S9Q5Q507d8Zzzz2nfIfw9xM3Dh065JPPIs8cOnQIdXV1kub56aefsGrVqhbfb+siD6msVisAIDo62qm9T58+yMvLQ01NjdubhBN5Q1vnuTdfEJmYmIjExERfdAlz5szBnDlzfPJZJI7ULNVyjrLoJPTt29fjZxCTftXV1aGqqkr0M6ajoqJgMpkU7pUzu92OkJAQlye4GI1GCIIAm83GopMUI/fG8aQPUrJU6znq96Lz+++/hyAIaNeunb+7QqRL9fX1MBgMGDx4sOR5y8rKWnw067m2bt2Kiy++2Otb4cQcJVIDX2Sp1nPU71evC4Ig+hmugiCgrq4uoJ/5Guhj5PjUR8p30B2DwSDq5Q9GoxF1dXWora11arfb7TAYDD7fY6AU5qizQB8jx6dOvshSf/Bmjvp9T2fzlnlsbGyb01ZVVeHgwYPo27evqJuZa1Ggj5HjU5/9+/fLmt+TE9N9pfkcpF9++cXpSStWqxXdu3cPmEPrzFFngT5Gjk+dAjVLvZmj6hwhEWmGmvd0xsfHo1OnTigoKHC01dfXY8eOHXzGNBGpih5y1O97OolI23wVhNXV1fjss88AAL///jsqKyuxfft2AMDll1+OiIgIpKam4vjx447beLRv3x5paWnIyclBREQELBYLNm3ahPLycj7piohUxRdZ6u8cZdFJRB6TsvUtN1BPnTqFefPmObU1//zqq69i2LBhaGpqQmNjo9M0s2bNgiAIWLdunePxbWvXrkWvXr1k9YeIyFvEZqnWc5RFJxHJ4qs9nWLu3Zqfn+/SZjAYkJaWhrS0NKW6RkQkmy+y1N85yqKTiGTx13lGRESBRA9ZKvlCopKSEkyfPh1xcXFITExEdna25KeSEFHgCAoKEvWi/8ccJaJz6SFHJe3ptNlsSE1NhdlsRk5ODsrKypCVlYWamhosWrRIqT4SkYoFQhD6EnOUiNzRQ5ZKKjo3b96Ms2fPIjc3F+Hh4QCAxsZGLF68GGlpaYiKilKij0SkYno4JORNzFEickcPWSqprC4sLERCQoIjKAEgOTkZTU1NKCoq8nbfiEjlxN6j05/3mFMb5igRnUsvOSppT6fVasXEiROd2oxGIyIjI2G1Wj3uhCAIqKqqanO66upqpz8DUaCPkeNTH0EQZAWZ1kPQ15ijygv0MXJ86sQsbZukotNut8NoNLq0m0wm2Gw2jztRX1+PgwcPip6+tLTU48/SikAfI8enLiEhIR7Pq4fzkLyJOeo7gT5Gjk99mKWtU8Utk9q1a4e+ffu2OV11dTVKS0thNpvRsWNHH/TM9wJ9jByf+hw5ckTW/HrYOtcC5uj/C/QxcnzqxCxtm6Si02g0oqKiwqXdZrPBZDJ53AmDwYDQ0FDR03fs2FHS9FoU6GPk+NRDbtDpISi9iTnqO4E+Ro5PXZilbZNUdEZHR7ucc1RRUYGTJ08iOjraqx0jIm3QQ1B6E3OUiNzRQ5ZKOoEgKSkJxcXFsNvtjrbt27cjKCgIiYmJXu8cEakbr16XjjlKROfSS45KKjpTUlIQFhaG9PR0fPHFF9iyZQuys7ORkpLCe8sR6VRwcLCoF/2NOUpE7ughRyUVnSaTCXl5eQgODkZ6ejqWL1+OSZMmITMzU6n+EZHK6WHr3JuYo0Tkjh5yVPLV63369MH69esV6AoRaVEgBKGvMUeJ6Fx6yFJV3DKJiLRLD0FJRKQ0PWQpi04ikkUPQUlEpDQ9ZCmLTiLymJTzjPQQqEREnhCbpVrP0cB/5hIRKSooKEjUi5RltVpFXYgQHx8PAIiPj+dFYEQqoocc5Z5OIpKFRQkRkXx6yFIWnUQkix6CkohIaXrIUhadRCRLIBzyISLyNz1kKYtOIvKYwWAQHZR62IonIvKE2CzVeo6y6CQiWbQegkREaqCHLGXRSUSy6CEoiYiUpocsZdFJRLLo4TwkIiKl6SFLWXQSkSx62DonIlKaHrKURScReYwXEhERyccLiYiIRNB6CBIRqYEespRFJxHJooegJCJSmh6ylEUnEckSHBzs7y4QEWmeHrKURScReYzndBIRycdzOomIRNB6CBIRqYEespRFJxHJood7yxERKU0PWRr4IyQiRRkMBlEvuUpKSjB9+nTExcUhMTER2dnZqKura3O+M2fOYNGiRRgxYgTi4uIwbtw4bNq0SXZ/iIi8SQ85yj2dRCSLLw4J2Ww2pKamwmw2IycnB2VlZcjKykJNTQ0WLVrU6rzz5s2D1WrFfffdh27duqGwsBCPP/44goODMWXKFMX7TkQkhtJZqoYcZdFJRLL44pDQ5s2bcfbsWeTm5iI8PBwA0NjYiMWLFyMtLQ1RUVFu5zt58iR2796NJ598EhMmTAAAJCQkYP/+/fjggw9YdBKRaiidpWrIUR5eJyKPiT20LvfQUGFhIRISEhxBCQDJycloampCUVFRi/M1NDQAADp37uzU3qlTJwiC4HF/iIi8SS85yj2dRCSLlK3zP/74A/Pnz2/x/V27drltt1qtmDhxolOb0WhEZGQkrFZri8vr1q0bhg8fjlWrVuHiiy/GhRdeiMLCQhQVFeHf//636H4TESlNbJZqOUdZdBKRLL44p9Nut8NoNLq0m0wm2Gy2VufNyclBRkYGxo4dC+DvGzA/8sgjuO666xTpKxGRJ5TOUjXkKItOIpJFylM0unXr1uJWuBIEQcDChQtRWlqK5cuXIzIyEsXFxXjiiSdgMpkcAUpE5G9is1TLOcqik4hk8cWeTqPRiIqKCpd2m80Gk8nU4nyffvoptm/fjm3btiEmJgYAMGzYMJw6dQpZWVksOolINZTOUjXkKC8kIiKPNT+6TcxLTqBGR0e7nHNUUVGBkydPIjo6usX5jhw5guDgYFgsFqf2fv364c8//0R1dbXHfSIi8haxWar1HGXRSUSy+OLm8ElJSSguLobdbne0bd++HUFBQUhMTGxxvh49eqCxsRGHDh1yaj9w4AC6dOmCjh07yuoXEZG36CFHWXQSkSy+KDpTUlIQFhaG9PR0fPHFF9iyZQuys7ORkpLidG+51NRUjB492vFzUlISunfvjrlz5+Ldd9/Fl19+iaeffhpbt27FbbfdJqtPRETepIcc5TmdRCSLL24ObzKZkJeXhyVLliA9PR1hYWGYNGkSMjIynKZrampCY2Oj4+dOnTph/fr1ePbZZ/Hvf/8bFRUV6NmzJzIzM1l0EpGqKJ2lashRFp1EJIsvLiQCgD59+mD9+vWtTpOfn+/S1rt3bzz33HPKdIqIyEt8kaX+zlFJRWdBQQG2bduGAwcOwG63o3fv3rj99tsxceJEn/3HQ0Tq0Xzyu9hpiTlKRK7EZqnWM0JS0bl+/Xr06NEDmZmZOP/881FcXIxHH30UJ06cwL333qtUH4lIxbQegr7GHCUid/SQpZKKzhdffBERERGOnxMSElBeXo5XXnkF99xzj0/O7SIidZFyc3hijhKRe3rIUknp9s+gbNavXz9UVlaiqqrKa50iIu3wxdXrgYQ5SkTu6CFHZV9I9N133yEqKgqdOnXyeBmCIIgK2+YbkAbyDZ0DfYwcn/oIgiArzAIhCP3NGzl63nnnOZ4W0hqz2ez0pxhaK4a1+D2UguNTJ2Zp22QVnd9++y0+/PBDPPjgg7I6UV9fj4MHD4qevrS0VNbnaUGgj5HjU5eQkBCP5pOy9a2HQPWEt3I0KioKGzZsED39smXLRE8rJZ/VRGvfQ6k4PvVROku1nqMeF50nTpxARkYGhg0bhjvuuENWJ9q1a4e+ffu2OV11dTVKS0thNpsD9kkigT5Gjk99jhw5Imt+rYegP3kzR8vKyrBgwYI2pzObzVi2bBkefvhh0f+p79mzR1bffE2L30MpOD51Ypa2zaOi0263Y9asWQgPD0dOTo7sE98NBgNCQ0NFT9+xY0dJ02tRoI+R41MPuUGnh6BUgrdztKGhweUxda0pLS0VPb1W/i2fS0vfQ09wfOrCLG2b5KKzpqYGaWlpqKiowOuvv47OnTsr0S8i0gg9BKW3MUeJ6Fx6yFJJRWdDQwPmz58Pq9WKDRs2OD2rk4j0SQ9B6U3MUSJyRw9ZKqnoXLx4MT755BNkZmaisrISe/fudbzXv39/j0+gJSLt4n0lpWGOEpE7eshSSUVnUVERACArK8vlvV27dqFnz57e6RURaQIfgykdc5SIzsXHYLrx8ccfK9UPItIorYegrzFHicgdPWSp7JvDE5G+6SEoiYiUpocsZdFJRLLoISiJiJSmhyxl0UlEsughKImIlKaHLA38S6WISFHNj29r60XKio6OhiAIbb6any60Z88eUdM3P09aS6/4+Hg/rw394PrzHj3kKPd0EpEsgRCERET+pocsZdFJRB6TsvWth0AlIvKE2CzVeo6y6CQiWbQegkREaqCHLGXRSUSy6OEpGkREStNDlrLoJCJZ9LB1TkSkND1kKYtOIpJFD0FJRKQ0PWQpi04ikkUPQUlEpDQ9ZCmLTiLyGK9eJyKSj1evExGJoPUQJCJSAz1kKYtOIpJFD0FJRKQ0PWQpi04ikkUPQUlEpDQ9ZCmLTiKSRQ9BSUSkND1kKYtOIpJFDzc0JiJSmh6ylEUnEcmih61zIiKl6SFLWXQSkcd4yyQiIvl4yyQiIhG0HoJERGqghywN/BMIiEhRQUFBol5ylZSUYPr06YiLi0NiYiKys7NRV1cnat6ysjI8+OCDuOKKKzBw4EAkJydj27ZtsvtEROQteshR7ukkIll8sXVus9mQmpoKs9mMnJwclJWVISsrCzU1NVi0aFGr8/7555+45ZZbcPHFF2PJkiXo1KkTDh8+LDpoiYh8QeksVUOOsugkIll8UXRu3rwZZ8+eRW5uLsLDwwEAjY2NWLx4MdLS0hAVFdXivE8//TQuvPBCrFmzBsHBwQCAhIQExftMRCSF0lmqhhzl4XUikqX5BPi2XnIUFhYiISHBEZQAkJycjKamJhQVFbU4X2VlJQoKCjBt2jRHUBIRqZEecpR7OonIY1KvXv/jjz8wf/78FqfZtWuX23ar1YqJEyc6tRmNRkRGRsJqtba4vAMHDqC+vh7nnXcebrvtNnz//fcIDw/H+PHjMX/+fLRr105U34mIlCTl6nUt5yj3dBKRLL7Y02m322E0Gl3aTSYTbDZbi/P99ddfAIBHHnkEl156KdauXYvU1FTk5eVh5cqVsvpERMqKj48XnS9SXmqlhxzlnk4ikkXKFZXdunVrcStcCU1NTQCAK6+8EpmZmQCAK664AmfPnsW6deuQnp6ODh06+Kw/REQtEZulWs5R7ukkIll8sXfBaDSioqLCpd1ms8FkMrU6H/B3QP5TQkIC6urq8Ouvv8rqFxGRt+ghR7mnk4hk8cXhqujoaJdzjioqKnDy5ElER0e3OF/fvn1bXW5tba1X+kdEJJfSWaqGHOWeTiKSxRd7OpOSklBcXAy73e5o2759O4KCgpCYmNjifD169IDFYkFxcbFTe3FxMTp06NBmmBIR+YoecpRFJxF5zGAwiH4ikZzATElJQVhYGNLT0/HFF19gy5YtyM7ORkpKitO95VJTUzF69GineTMyMvDxxx9j2bJlKCoqwqpVq7Bu3TrceeedCA0N9bhPRETeIjZLtZ6jPLxORLL44vC6yWRCXl4elixZgvT0dISFhWHSpEnIyMhwmq6pqQmNjY1ObaNGjcIzzzyDF154AZs2bULXrl0xZ84c3H333Yr3m4hILKWzVA05KqvoPHv2LJKTk1FWVoa33noLsbGxchZHRBrkq1uQ9OnTB+vXr291mvz8fLft119/Pa6//noFeiUfc5SIAN9kqb9zVFbR+cILL7hUw0SkL2q+750WMEeJCNBHlnp8TmdJSQk2btyIOXPmeLM/RKQxWr8hsz8xR4momR5y1OM9nUuXLkVKSgouvvhib/aHiDRGys3hyRlzlIia6SFLPSo6t2/fjp9//hk5OTk4cOCA7E4IgoCqqqo2p6uurnb6MxAF+hg5PvURBEHWFnQgbH37g5ZyNCYmxuN++YPZbAagre+hFGrKGSX+bTSvv+Y/vU3M98QTzNK2SS46q6urkZWVhYyMDHTq1Mkrnaivr8fBgwdFT19aWuqVz1WzQB8jx6cuISEhHs0n5ZCPHgJVLK3l6IYNGzzokf9p7XsolRrGp+S/jWXLlimyXCnfE6mUzlKt56jkovPFF19Ely5dMHHiRK91ol27dqJuLlpdXY3S0lKYzWZ07NjRa5+vJoE+Ro5PfY4cOSJrfq2HoD9oLUfj4+Plds+nzGYzli1bpqnvoRRqyhkl/m00r7+HH35YkcJ6z549Xl8mwCwVQ1LR+fvvv2PdunV4/vnnHc/vbN5NXVVVhbNnzyIsLExyJwwGg6Sbi3bs2DHgb+oc6GPk+NRDbtDp4Twkb9Jijh46dEhyf9RAS99DT6hhfEr+2ygtLVVk+Ur9zpilbZNUdB47dgz19fVubwZ6xx13YNCgQXjjjTe81jkiUj89bJ17E3OUiNzRQ5ZKKjr79euHV1991ant4MGDePLJJ7F48WLe1JhIh/QQlN7EHCUid/SQpZKKTqPRiGHDhrl9b8CAARgwYIBXOkVE2qGHoPQm5igRuaOHLOWz14nIY7x6nYhIPl69LtKwYcM0e5I5Ecmnh5PflcYcJSI9ZCn3dBKRLFrf8iYiUgM9ZCmLTiKSRQ9BSUSkND1kKYtOIpJFD0FJRKQ0PWRp4J9AQESKCgoKEvUiZVmtVsfFCK29mp8gEx8fL2p6g8EAQRAUeRHR/9NDjnJPJxF5jFevExHJx6vXiYhE0HoIEhGpgR6ylEUnEcmih6AkIlKaHrKURScRyRII5xkREfmbHrKURScRyaKHoCQiUpoespRFJxF5jBcSERHJxwuJiIhE0HoIEhGpgR6ylEUnEcmih0NCRERK00OWsugkIln0sHVORKQ0PWQpi04ikkUPQUlEpDQ9ZCmLTiKSRQ9BSUSkND1kKYtOIvKYwWAQfR6SHgKViMgTYrNU6znKopOIZNF6CBIRqYEespRFJxHJooegJCJSmh6ylEUnEcmih9t8EBEpTQ9ZyqKTiGTRQ1ASESlND1nKopOIPMbHYBIRyaeXx2AGfllNRIpqDsu2XnKVlJRg+vTpiIuLQ2JiIrKzs1FXVydpGevXr0dMTAzS0tJk94eIyJv0kKPc00lEsvhiy9tmsyE1NRVmsxk5OTkoKytDVlYWampqsGjRIlHLOHnyJJ5//nl06dJF4d4SEUmndJaqIUdZdBKRLL44D2nz5s04e/YscnNzER4eDgBobGzE4sWLkZaWhqioqDaX8fTTT2PUqFE4fvy4wr0lIpJO6SxVQ47y8DoRyeKLw+uFhYVISEhwBCUAJCcno6mpCUVFRW3O/+233+Kjjz7CggULZPWDiEgpeshR7ukkIlmkBOEff/yB+fPnt/j+rl273LZbrVZMnDjRqc1oNCIyMhJWq7XVz2xsbMSSJUswe/ZsdO3aVXRfiYh8SWyWajlHWXQSkSy+OKfTbrfDaDS6tJtMJthstlbn3bhxI6qrq3HnnXcq1Dt1iI6OhiAIbU5XVVWFgwcPYs+ePQgNDRW1bK1fMetNSv4uxKw/tVGiz578G5VCqXX4zjvvIDo62uP5lf6eqSFHWXQSkccMBgOCg4NFT9utW7cWt8KVcOrUKaxcuRJPPfUUQkJCfPa5RERSiM1Srecoi04iksUXe8GMRiMqKipc2m02G0wmU4vzrVixAjExMbjssstgt9sBAA0NDWhoaIDdbkdoaCjOO48xSET+p3SWqiFHmbZEJIsvis7o6GiXc44qKipw8uTJVg9n/fLLL/jmm28wdOhQl/eGDh2K1atXIykpyev9JSKSSuksVUOOsugkIll8UXQmJSVh1apVTuckbd++HUFBQUhMTGxxvoceesixZd7siSeeQIcOHXDfffchJiZG0X4TEYmldJaqIUdZdBKRxwwGg+h7y8kJ1JSUFOTn5yM9PR1paWkoKytDdnY2UlJSnO4tl5qaiuPHj2Pnzp0AgH79+rksy2g0IjQ0FMOGDfO4P0RE3iQ2S7Weox7dp3Pr1q0YP348YmNjMWzYMNx1112oqanxZFFEpHG+uE+nyWRCXl4egoODkZ6ejuXLl2PSpEnIzMx0mq6pqQmNjY2yPstXmKNE9E96yFHJezpffPFFrF69GrNnz0ZcXBzOnDmDL7/8UjNBT0Ta1KdPH6xfv77VafLz89tcjphplMYcJSJ/8HeOSio6rVYrcnNz8cILL+Dqq692tF933XUefTgRaR/v4SgNc5SI3NFDlkoqOt9++2307NnTKSiJSN/0EJTexBwlInf0kKWSis59+/bBYrHghRdeQH5+PioqKnDppZdi4cKFGDRokMedEAQBVVVVbU5XXV3t9GcgCvQxcnzqIwiCrLATeyER/U2LOaq1q/zNZjMAZb6HSv4uxKw/QJs5I4XS41NqHcq9cboestQgSHiG1ZgxY1BWVoauXbsiIyMDHTt2xKpVq/Dzzz9jx44d6NKli+QO7N+/H3V1dZLnIyLvCQkJQWxsrKR59u/fj5qaGtTW1oqavn379ujQoYPkzwk0zFGiwKV0lmo9RyXt6Wzekl6xYgUuueQSAMCgQYMwatQovPbaa5g3b55HnWjXrh369u3b5nTV1dUoLS2F2WxGx44dPfostQv0MXJ86nPkyBFZ8+vhkJA3aTFH4+PjPeqTv5jNZixbtkyR76GSv4s9e/aImk6LOSOF0uNTah0+++yz6Nmzp8fz6yFLJRWdRqMR4eHhjqAEgPDwcPTv31/Wf1wGgwGhoaGip+/YsaOk6bUo0MfI8amHnKCTchsPPQSqGFrM0UOHDnnaLb9S4nuo5O9Cal+1lDOeUGp8Sq1DOUcbxGap1nNU0gkErW1Fiz3ERkSkZ8xRItIrSUXnyJEjUV5ejoMHDzrazpw5gwMHDmDAgAFe7xwRqZ8vbg4fSJijROSOHnJU0uH1a6+9FrGxsZg7dy4yMjLQvn17vPzyywgJCcG0adOU6iMRqVggBKEvMUeJyB09ZKmkojMoKAgvv/wynnzySSxatAj19fW47LLLsGHDBkRGRirVRyJSMT0EpTcxR4nIHT1kqeTHYEZERODpp59Woi9EpEF6CEpvY44S0bn0kKWSi04ion/Sww2NiYiUpocsZdFJRB7Tw5Y5EZHS9JKlgV9WExEREZHfqaLotFqtom4V0PwUgfj4eN6mhUgl+F0MfIIgaOol9sk+avtdkG8otf6io6Nl9UsPOcrD60Qki9gg5H+qREQtE5OlWs9RFp1EJEsgbH0TEfmbHrKURScRyaKHoCQiUpoespRFJxHJooegJCJSmh6ylEUnEcmih6AkIlKaHrKURScRyaKHoCQiUpoespRFJxF5TMptPPQQqEREnhCbpVrPURadRCSL1kOQiEgN9JClLDqJSBY9BCURkdL0kKUsOolIFj0EJRGR0vSQpSw6iUgWPQQlEZHS9JClLDqJSBY9BCURkdL0kKUsOolIFj0EJRGR0vSQpUH+7gARERERBT7u6SQiWfSwdU5EpDQ9ZCmLTiLyGG8OT0QkH28OT0QkgtZDkIhIDfSQpSw6iUgWPQQlEZHS9JClLDqJSBZfBWVJSQmWLl2K77//HmFhYbjpppswf/58hISEtDjPn3/+ifXr16OoqAi//fYbOnfujKFDh+K+++5Djx49fNJvIiIxfJGl/s5RFp1EpHo2mw2pqakwm83IyclBWVkZsrKyUFNTg0WLFrU434EDB7Bz505MnDgRgwYNwpkzZ/Diiy9i8uTJeP/99xEREeHDURAR+Y8acpRFJxHJ4out882bN+Ps2bPIzc1FeHg4AKCxsRGLFy9GWloaoqKi3M43ZMgQFBQU4Lzz/j/q4uPjMWLECLzzzjuYMWOG4n0nIhJD6SxVQ47yPp1EJEvzVZdtveQoLCxEQkKCIygBIDk5GU1NTSgqKmpxPqPR6BSUAHDhhRciIiICf/75p6w+ERF5kx5ylHs6ichn/vjjD8yfP7/F93ft2uW23Wq1YuLEiU5tRqMRkZGRsFqtkvrwyy+/4NSpU+jTp4+k+dTOarVi4MCBbU4XExODDRs2ID4+HocOHRK1bEEQ5HaPiLxEyznKopOIZPHF4XW73Q6j0ejSbjKZYLPZRC9HEAQsXboUXbt2xdixY73ZRSIiWZTOUjXkKItOIvKYwWBAUJC4s3QMBgO6devW4la4L+Tk5OCrr77CmjVrEBoa6rd+EBH9k9gs1XqOsugkItUzGo2oqKhwabfZbDCZTKKW8cYbb+D555/HsmXLkJCQ4O0uEhGpmhpylEUnEcnii8Pr0dHRLuccVVRU4OTJk4iOjm5z/p07d+Lxxx/H3LlzMWnSJKW6SUTkMaWzVA05yqvXiUgWX1y9npSUhOLiYtjtdkfb9u3bERQUhMTExFbn3b17N+677z5MnjwZ6enpsvpBRKQUPeSo5KJz165dmDx5MgYPHozhw4dj3rx5OHr0qMcdICJt80XRmZKSgrCwMKSnp+OLL77Ali1bkJ2djZSUFKd7y6WmpmL06NGOn0tKSpCeng6z2YybbroJe/fudbx+++03WX2SgzlKROfSQ45KOry+e/du3HvvvRg/fjwyMjJQXl6OFStWYMaMGXjvvffQoUMHSR9ORCSGyWRCXl4elixZgvT0dISFhWHSpEnIyMhwmq6pqQmNjY2On/ft24eKigpUVFRg6tSpTtPefPPNyMrK8kn//4k5SkT+oIYclVR0fvDBB+jevTueeOIJR8UdERGB1NRU/Pjjj7jsssukLI6IAoCvnr3ep08frF+/vtVp8vPznX6eMGECJkyYoGCvpGOOEpE7vshSf+eopKKzoaEBYWFhTr+Yzp07A+DNg4n0yldFZ6BgjhKRO3rIUklF54QJE/Duu+9iw4YNuPHGG1FeXo5nnnkG/fv3R3x8vOedOO88xMTEtDmd2Wx2+lOMqqoqD3vlH9XV1U5/BhqOT30EQdBF2KkFc1R5WvweSsHxqROztG0GQeKm9SeffIIFCxbg7NmzAIB+/fphzZo1uOCCCzzqwP79+1FbW8sVReRHISEhiI2NlTTP/v370dTUhB49eoia/vfff0dQUJDkzwlEzFGiwKR0lmo9RyXt6dyzZw8eeOABTJkyBSNGjEB5eTleeOEF3H333di4caPHJ8CXlZVhwYIFbU5nNpuxbNkyPPzwwygtLRXdZy2prq5GaWkpzGYzOnbs6O/ueB3Hpz5HjhyRNT8LHWmYo8rT4vdQCo5PnZilbZNUdC5duhRXXHEFMjMzHW1xcXEYMWIE3n33Xdxyyy0edaKhoQGHDh0SPX1paano6bX6qLuOHTtqtu9icHzqoYegUxPmqO9o6XvoCY5PXZilbZN0n86SkhJccsklTm0XXnghzj//fL/e846I/McX9+kMJMxRInJHDzkqaU9n9+7d8d///tep7ffff8eZM2dEn9dFRIElEILQl5ijROSOHrJU0p7OlJQUfPTRR1i6dCmKi4vx4YcfYvbs2ejSpQuSk5OV6iMRUcBgjhKRXkna03nHHXcgJCQEmzZtwpYtWxAWFoa4uDg899xzOP/885XqIxGpmB62zr2JOUpE7ughSyUVnQaDAVOnTnV5DBIR6ZcegtKbmKNE5I4eslTS4XUiIiIiIk9I2tNJRHQuPWydExEpTQ9ZyqKTiDwm5TYeeghUIiJPiM1SrecoD68TEQWA6OhoCILQ5qv56UJ79uwRNb3EJyWTDGLveRsfHw8AiI+P9/t9csV+vpRX8/go8HBPJxHJovUtbyIiNdBDlnJPJxEREREpjns6iUgWPWydExEpTQ9Zyj2dRERERKQ47ukkIln0sHVORKQ0PWQp93QSERERkeK4p5OIZNHD1jkRkdL0kKUsOolIFj0EJRGR0vSQpTy8TkRERESKY9FJRERERIrj4XUikkUPh4SIiJSmhyzlnk4iIiIiUhz3dBKRLHrYOiciUpoespR7OomIiIhIcdzTSUQeMxgMorfO9bAVT0TkCbFZqvUc5Z5OIiIiIlIc93QSkSxa3/ImIlIDPWQpi04ikkUPQUlEpDQ9ZCkPrxMRERGR4rink4hk0cPWORGR0vSQpdzTSUSaUFJSgunTpyMuLg6JiYnIzs5GXV1dm/MJgoCXX34ZI0aMwMCBA3HLLbdg7969yneYiEhl/J2jft/TWV9fjwsvvBDvvPNOm9OGhIQAAJ599llRvyQA2L9/v5zu+ZwgCACAI0eOBORWD8enPnV1dbL66otx2mw2pKamwmw2IycnB2VlZcjKykJNTQ0WLVrU6ryrV6/GypUrcf/99yMmJgYbNmzAjBkz8O6776JXr16K990X6uvrIQiCqLzT4r9RqbQ6RjH/DwLq+r9QbJ+laB6f1taf2rNUDTnq96LTYDCgXbt2iI6OFj1Pz549FeyRfxkMBscXLhBxfOoj5V6b/rJ582acPXsWubm5CA8PBwA0NjZi8eLFSEtLQ1RUlNv5amtr8dJLL2HGjBm48847AQBDhgzBmDFjsHbtWjz++OO+GYDCpKw/Lf4blUqrY5Ty/yCgjv8LpfY5kKk9S9WQo34vOgcPHuzvLhCRDL4I2cLCQiQkJDiCEgCSk5Px2GOPoaioCBMmTHA73549e1BZWYnk5GRHW0hICEaPHo2dO3cq3W2fYY4SaZ/SWaqGHPV70UlE2lVXVyf6sF1dXR1OnTqF+fPntzjNrl273LZbrVZMnDjRqc1oNCIyMhJWq7XF5TW/d+7emD59+iAvLw81NTXo0KGDqP4TESlFbJZqPUd5IREReSQkJETSIcyQkBDYbDaPPstut8NoNLq0m0ymVpdpt9sREhKC9u3bO7UbjUYIguBxf4iIvEVKlmo9R7mnk4g8EhMTI3me2NhYTJ48WYHeEBFpk9Qs1XKOck8nEame0WhERUWFS7vNZoPJZGp1vrq6OtTW1jq12+12GAyGVuclIgokashRFp1EpHrR0dEu5xxVVFTg5MmTrV492/zeL7/84tRutVrRvXt3ns9JRLqhhhxl0UlEqpeUlITi4mLY7XZH2/bt2xEUFITExMQW54uPj0enTp1QUFDgaKuvr8eOHTuQlJSkaJ+JiNREDTnKczqJSPVSUlKQn5+P9PR0pKWloaysDNnZ2UhJSXG6t1xqaiqOHz/uuI1H+/btkZaWhpycHERERMBisWDTpk0oLy/HzJkz/TUcIiKfU0OOsugkItUzmUzIy8vDkiVLkJ6ejrCwMEyaNAkZGRlO0zU1NaGxsdGpbdasWRAEAevWrcPp06fRr18/rF27NmCeRkREJIYactQgND8vjIiIiIhIITynk4iIiIgUx6KTiIiIiBTHopOIiIiIFKeaC4lKSkqwdOlSfP/99wgLC8NNN92E+fPnt/loKEEQsHr1amzcuNFxcuvChQsRFxfnm46LVFBQgG3btuHAgQOw2+3o3bs3br/9dkycOBEGg6HF+UaNGoXff//dpf2HH35weSSVP7399ttYuHChS/usWbNw//33tzifVtbf7bffjq+//trte8888wzGjh3r9j2trD8KDMxR97TyPQz0HAWYpXqniqLTZrMhNTUVZrMZOTk5KCsrQ1ZWFmpqarBo0aJW5129ejVWrlyJ+++/HzExMdiwYQNmzJiBd999V1VXp65fvx49evRAZmYmzj//fBQXF+PRRx/FiRMncO+997Y673XXXYcZM2Y4tUl55rUvrVmzBp07d3b8/M/bMLijlfX32GOPobKy0qktLy8PO3bsQEJCQqvzamn9kXYxR5mjal9/ALNU9wQVWLVqlRAXFyecOXPG0bZ582ahX79+wokTJ1qcr6amRoiPjxeWL1/uaKutrRVGjhwpPPbYYwr2WLpTp065tD3yyCNCfHy80NjY2OJ8I0eOFBYvXqxk17xiy5YtgsVicTvOlmhp/bkzatQoYdasWa1Oo5X1R9rHHGWONlPr+msJs1Q/VHFOZ2FhIRISEhAeHu5oS05ORlNTE4qKilqcb8+ePaisrERycrKjLSQkBKNHj0ZhYaGSXZYsIiLCpa1fv36orKxEVVWVH3rkf1paf+fas2cPjh07hhtuuMHfXSECwBxljqp//bnDLNUXVRSdVqvV5bmfRqMRkZGRLs8JPXc+AC7z9unTB8ePH0dNTY33O+tF3333HaKiotCpU6dWp3vvvfdw6aWXYvDgwZg1axYOHTrkox5KN27cOPTr1w/XXHMNXnrpJZcbzP6Tltff+++/j9DQUFxzzTVtTqul9UfaxRxljv6TVtYfs1RfVHFOp91uh9FodGk3mUyw2WytzhcSEuJyErHRaIQgCLDZbJIeRO9L3377LT788EM8+OCDrU43atQoDBw4EN27d8fRo0exatUqTJs2De+8846qztWJjIzEnDlzMGjQIBgMBnz88cd47rnnUFZW1uL5ZFpdfw0NDSgoKMCoUaMQGhra6rRaWX+kfczRlmnle6inHAWYpXqkiqJTb06cOIGMjAwMGzYMd9xxR6vTPvLII46/X3bZZUhMTERycjLWrl2Lxx9/XOGeinfVVVfhqquucvw8fPhwtG/fHnl5eZg9eza6du3qx955V1FREU6fPo1x48a1Oa1W1h+R1jBHtY9Zqj+qOLxuNBpRUVHh0m6z2WAymVqdr66uDrW1tU7tdrsdBoOh1Xn9xW63Y9asWQgPD0dOTg6CgqStgq5du2LIkCE4cOCAQj30nuTkZDQ2NuLgwYNu39fi+gP+PhwUHh6O4cOHS55XS+uPtIU5Kp6WvoeBmqMAs1SPVFF0RkdHu5xzVFFRgZMnT7qcp3LufADwyy+/OLVbrVZ0795ddYcUampqkJaWhoqKCpdbYuiR1tYf8Pc6/OijjzBmzBi0a9fO390hcmCO6pPW1l8zZqk+qaLoTEpKQnFxMex2u6Nt+/btCAoKQmJiYovzxcfHo1OnTigoKHC01dfXY8eOHUhKSlK0z1I1NDRg/vz5sFqtWLNmTZv3XWtJWVkZvvvuO8TGxnq5h9734YcfIjg4GP3793f7vpbWX7OPP/4YVVVVHl9pqaX1R9rCHBVPS9/DQMxRgFmqV6o4pzMlJQX5+flIT09HWloaysrKkJ2djZSUFKdQSU1NxfHjx7Fz504AQPv27ZGWloacnBxERETAYrFg06ZNKC8vx8yZM/01HLcWL16MTz75BJmZmaisrMTevXsd7/Xv3x8hISEu43v//ffxySef4Oqrr0bXrl1x9OhRvPzyywgODsb06dP9NBL3Zs6ciWHDhiEmJgYAsGvXLrzxxhu44447EBkZCUDb66/Ze++9h+7du2PIkCEu72l5/ZH2MUeZo2pff//ELNUnVRSdJpMJeXl5WLJkCdLT0xEWFoZJkyYhIyPDabqmpiaXW0fMmjULgiBg3bp1jsd/rV27VnVXszXfJy8rK8vlvV27dqFnz54u4+vZsyf+/PNPPPHEE6ioqEDnzp1xxRVXYO7cuaob38UXX4wtW7bgxIkTaGpqgtlsxkMPPYTbb7/dMY2W1x/w97lxn3/+OVJTU90+ck/L64+0jznKHFX7+mvGLNUvgyAIgr87QURERESBTRXndBIRERFRYGPRSURERESKY9FJRERERIpj0UlEREREimPRSURERESKY9FJRERERIpj0UlEREREimPRSURERESKY9FJRERERIpj0UlEREREimPRSURERESK+z8OMwMCyJlbtgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fdr': 0.6667, 'tpr': 0.05, 'fpr': 0.08, 'shd': 21, 'nnz': 3, 'precision': 0.3333, 'recall': 0.05, 'F1': 0.087, 'gscore': 0.0}\n",
      "{'fdr': 0.7667, 'tpr': 0.35, 'fpr': 0.92, 'shd': 30, 'nnz': 30, 'precision': 0.2333, 'recall': 0.35, 'F1': 0.28, 'gscore': 0.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# Now use a threshold of 0.3 to binarize the weighted adjacency matrix W\n",
    "W_est = np.array(model.get_W())\n",
    "B_est = compute_binary_adjacency(W_est, threshold=0.3)\n",
    "\n",
    "W_fix = ensure_DAG(W_est)\n",
    "B_fix = 1.0*(W_fix != 0)\n",
    "\n",
    "# %%\n",
    "# Check if B_est is indeed a DAG\n",
    "def is_dag(adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Check if a given adjacency matrix represents a Directed Acyclic Graph (DAG).\n",
    "    \n",
    "    Parameters:\n",
    "        adjacency_matrix (numpy.ndarray): A square matrix representing the adjacency of a directed graph.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the graph is a DAG, False otherwise.\n",
    "    \"\"\"\n",
    "    # Create a directed graph from the adjacency matrix\n",
    "    graph = nx.DiGraph(adjacency_matrix)\n",
    "    \n",
    "    # Check if the graph is a DAG\n",
    "    return nx.is_directed_acyclic_graph(graph)\n",
    "\n",
    "# Example usage:\n",
    "adj_matrix = np.array([\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [1, 0, 0]\n",
    "])\n",
    "\n",
    "print(is_dag(adj_matrix))  # Output: False, since the graph has a cycle.\n",
    "\n",
    "# Check if the estimated binary adjacency matrix B_est is a DAG\n",
    "is_dag_B_est = is_dag(B_est)\n",
    "print(f\"Is the estimated binary adjacency matrix a DAG? {is_dag_B_est}\")\n",
    "\n",
    "# Define fucntion to compute h_reg based W with h_reg = jnp.trace(jax.scipy.linalg.expm(W * W)) - d, here * denotes the hadamard product\n",
    "def compute_h_reg(W):\n",
    "    \"\"\"This function computes the h_reg term based on the matrix W.\"\"\"\n",
    "    h_reg = jnp.trace(jax.scipy.linalg.expm(W * W)) - W.shape[0]\n",
    "    return h_reg\n",
    "\n",
    "# Compute the h_reg term for the true weighted adjacency matrix W_true\n",
    "h_reg_true = compute_h_reg(W_true)\n",
    "print(f\"The h_reg term for the true weighted adjacency matrix W_true is: {h_reg_true:.4f}\")\n",
    "# Compute the h_reg term for the estimated weighted adjacency matrix W_est\n",
    "h_reg_est = compute_h_reg(W_est)\n",
    "print(f\"The h_reg term for the estimated weighted adjacency matrix W_est is: {h_reg_est:.4f}\")\n",
    "h_reg_fix = compute_h_reg(W_fix)\n",
    "print(f\"The h_reg term for the fixed weighted adjacency matrix W_fix is: {h_reg_fix:.4f}\")\n",
    "\n",
    "# We note that B_est is a DAG even though h_reg is not equal to 0.0 (but only close to 0.0). \n",
    "# This is because the matrix exponential is not a perfect measure of the DAG constraint, but it is a good approximation.\n",
    "\n",
    "# %%\n",
    "# print first 5 rows and columsn of W_est and round values to 4 decimal places and show as non-scientific notation\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "print(\"The first 5 rows and columns of the estimated weighted adjacency matrix W_est\\n{}\".format(W_est[:5, :5]))\n",
    "\n",
    "# %%\n",
    "# now show the adjacency matrix of the true graph and the estimated graph side by side\n",
    "plot_adjacency_matrices(B_true, B_est)\n",
    "\n",
    "# now show the adjacency matrix of the true graph and the estimated graph side by side\n",
    "plot_adjacency_matrices(B_true, B_fix)\n",
    "\n",
    "# %%\n",
    "print(np.sum(B_est))\n",
    "print(np.sum(B_fix))\n",
    "print(np.sum(B_true))\n",
    "\n",
    "# %%\n",
    "# plot est_dag and true_dag\n",
    "GraphDAG(B_est, B_true)\n",
    "# calculate accuracy\n",
    "met_pcax = MetricsDAG(B_est, B_true)\n",
    "print(met_pcax.metrics)\n",
    "\n",
    "met_pcax_fix = MetricsDAG(B_fix, B_true)\n",
    "print(met_pcax_fix.metrics)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcax24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
